{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ec69a2",
   "metadata": {},
   "source": [
    "# SEC Filing Predictive Model\n",
    "\n",
    "## Overview of this notebook\n",
    "\n",
    "### Preprocess Summary\n",
    "\n",
    "- Number of records: The reports with less than 500 word phrases are excluded. 44817 records are used in building our models. \n",
    "\n",
    "- Features Selection: After data exploration, the non-text features are excluded because they don't provide much value to our models but add complexity of data process and modeling. \n",
    "\n",
    "- Text Features Extraction: The text can generate 5,449,804 unique tokens which is too large to process. In the TFIDF process, I tried to keep the number of features below 100,000 to limit the computing power that is needed. The word phrases that are in 90% of the reports and the word phrases that are in less than 70 reports are excluded. The shape of the data we feed to the models is (44817, 97629). The Matrix transformed to CSR (Compressed Sparse Row) format to minimize ram usage. \n",
    "\n",
    "- Cross Validation: 20% of the data is set to be the test dataset. The Stratified K Fold is used to allocate the train and the test sets. \n",
    "\n",
    "#### Models (Traditional Machine Learning Classification)\n",
    "\n",
    "Five tradition classification model are run. The Logistic Regression has the higher accuracy. Below is the accuracy of each model.  \n",
    "\n",
    "- Logistic Regression - 73%\n",
    "- K-Nearest Neighbors - 65%\n",
    "- Random Forest - 72%\n",
    "- Support Vector Machine - 73% \n",
    "\n",
    "#### Models (Neural Network)\n",
    "\n",
    "- ANN-a: node: 64, learning rate = 0.001 (default), layer 1, dropout = 0 (default), batch size = 32\n",
    "    * Best Result: 1st epoch, train 72.54%, test 72.6%\n",
    "- ANN-b: node: 64, learning rate = 0.001 (default), layer 1, dropout = 0.8 (default), batch size = 32\n",
    "    * Best Result: 3rd epoch, train 72.58%, test 72.58%\n",
    "- ANN-c: node: 64, learning rate = 0.005 (default), layer 1, dropout = 0.2 (default), batch size = 32\n",
    "    * Best Result: 1st epoch, train 72.49%, test 72.55%\n",
    "- ANN-d: node: (1000, 500, 50), learning rate = 0.01, layer 3 , dropout = (0.5, 0.5, 0.5), batch size = 32\n",
    "    * Best Result: 1st epoch, train 72.47%, test 72.52%\n",
    "- RNN-LSTM: \n",
    "    * Limit the data set to the top 100,000 words.\n",
    "    * Set the max number of words in each reports at 2500.\n",
    "    * Result: train 72.53%, test 72.52% for each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d73ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 s, sys: 1.18 s, total: 6.46 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys  #system specific parameters and names\n",
    "import gc   #garbage collector interface\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf \n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee44d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbde465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7df1b1",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Load Data\n",
    "\n",
    "The index sec pickle file is loaded. It contains stock price, and the bag of word phrase of the reports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13f0ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 19.4 s, total: 37.6 s\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_in ='/Users/wailunchung/Documents/GitHub/Capstone_data/index_sec'\n",
    "import pickle as pickle\n",
    "with open(file_in, \"rb\") as fh:\n",
    "    data2 = pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba93fb2",
   "metadata": {},
   "source": [
    "### Run basic cleaning \n",
    "\n",
    "#### exclude short reports\n",
    "\n",
    "The reports with less than 500 word phrases are excluded to ensure they are the full reports. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62138e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.7 ms, sys: 236 ms, total: 288 ms\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove <500\n",
    "data2 = data2.loc[(data2['file_text_length'] >= 500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348bfd8",
   "metadata": {},
   "source": [
    "#### Response Variable\n",
    "\n",
    "Originality, the response variable is if the percentage change after 20 days of the reporting date is higher than 5 percent. The per_change_exceeding is calculated. \n",
    "\n",
    "The eact same filing could have a different response depending on the day it was filed. We adjust the response variable to reflect a relative performance between each company after 20 days of the reporting. We calculate the mean percentage change response for each week and subtract that value from each individual response. The adjusted percentage change can factor in the dynamic market conditions in the period. \n",
    "\n",
    "Response variable: the stock price after 20 days of filing exceed 5% of the average stock price change of the same period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ca8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get year and week of the filing\n",
    "data2['weeknum'] = data2['FileDate'].dt.week\n",
    "data2['year'] = data2['FileDate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ec976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearweek_average = data2.groupby(['year', 'weeknum']).agg({'Pct_Change_20':['mean', 'min', 'max']})\n",
    "yearweek_average.columns = ['Pct_Change_20_mean', 'Pct_Change_20_min', 'Pct_Change_20_max']\n",
    "yearweek_average = yearweek_average.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a827cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 171 entries, 0 to 170\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   year                171 non-null    int64  \n",
      " 1   weeknum             171 non-null    int64  \n",
      " 2   Pct_Change_20_mean  171 non-null    float64\n",
      " 3   Pct_Change_20_min   171 non-null    float64\n",
      " 4   Pct_Change_20_max   171 non-null    float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 6.8 KB\n"
     ]
    }
   ],
   "source": [
    "yearweek_average.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de4f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.merge(data2, yearweek_average,  how='left', left_on=['year','weeknum'], right_on = ['year','weeknum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe162fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['adj_Pct_Change_20'] = data2['Pct_Change_20'] - data2['Pct_Change_20_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6f6f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 ms, sys: 1.22 ms, total: 3.84 ms\n",
      "Wall time: 2.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get response \n",
    "data2['per_change_exceeding'] = np.where(data2['adj_Pct_Change_20'] > 5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74b64f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyCIK</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileDate</th>\n",
       "      <th>EdgarTextUrl</th>\n",
       "      <th>EdgarHtmlUrl</th>\n",
       "      <th>AccessionNumber</th>\n",
       "      <th>SecFileName</th>\n",
       "      <th>CompanyTicker</th>\n",
       "      <th>FileDate_ClosingPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>FileName</th>\n",
       "      <th>f_text</th>\n",
       "      <th>file_text_length</th>\n",
       "      <th>weeknum</th>\n",
       "      <th>year</th>\n",
       "      <th>Pct_Change_20_mean</th>\n",
       "      <th>Pct_Change_20_min</th>\n",
       "      <th>Pct_Change_20_max</th>\n",
       "      <th>adj_Pct_Change_20</th>\n",
       "      <th>per_change_exceeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717954</td>\n",
       "      <td>UNIFIRST CORP</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>edgar/data/717954/0001284084-19-000002.txt</td>\n",
       "      <td>edgar/data/717954/0001284084-19-000002-index.html</td>\n",
       "      <td>0001284084-19-000002</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>UNF</td>\n",
       "      <td>133.860001</td>\n",
       "      <td>...</td>\n",
       "      <td>717954_0001284084-19-000002.txt</td>\n",
       "      <td>[various estimate, the result, timely decision...</td>\n",
       "      <td>1870</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.403937</td>\n",
       "      <td>-5.583489</td>\n",
       "      <td>21.985292</td>\n",
       "      <td>-1.424262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1084765</td>\n",
       "      <td>RESOURCES CONNECTION INC</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>edgar/data/1084765/0001193125-19-001543.txt</td>\n",
       "      <td>edgar/data/1084765/0001193125-19-001543-index....</td>\n",
       "      <td>0001193125-19-001543</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>RGP</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1084765_0001193125-19-001543.txt</td>\n",
       "      <td>[asc topic contract term, limited number, the ...</td>\n",
       "      <td>2305</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.403937</td>\n",
       "      <td>-5.583489</td>\n",
       "      <td>21.985292</td>\n",
       "      <td>18.581354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CompanyCIK               CompanyName FileType   FileDate  \\\n",
       "0      717954             UNIFIRST CORP     10-Q 2019-01-03   \n",
       "1     1084765  RESOURCES CONNECTION INC     10-Q 2019-01-03   \n",
       "\n",
       "                                  EdgarTextUrl  \\\n",
       "0   edgar/data/717954/0001284084-19-000002.txt   \n",
       "1  edgar/data/1084765/0001193125-19-001543.txt   \n",
       "\n",
       "                                        EdgarHtmlUrl       AccessionNumber  \\\n",
       "0  edgar/data/717954/0001284084-19-000002-index.html  0001284084-19-000002   \n",
       "1  edgar/data/1084765/0001193125-19-001543-index....  0001193125-19-001543   \n",
       "\n",
       "  SecFileName CompanyTicker  FileDate_ClosingPrice  ...  \\\n",
       "0   2019-QTR1           UNF             133.860001  ...   \n",
       "1   2019-QTR1           RGP              13.600000  ...   \n",
       "\n",
       "                           FileName  \\\n",
       "0   717954_0001284084-19-000002.txt   \n",
       "1  1084765_0001193125-19-001543.txt   \n",
       "\n",
       "                                              f_text  file_text_length  \\\n",
       "0  [various estimate, the result, timely decision...              1870   \n",
       "1  [asc topic contract term, limited number, the ...              2305   \n",
       "\n",
       "   weeknum  year Pct_Change_20_mean  Pct_Change_20_min  Pct_Change_20_max  \\\n",
       "0        1  2019           3.403937          -5.583489          21.985292   \n",
       "1        1  2019           3.403937          -5.583489          21.985292   \n",
       "\n",
       "   adj_Pct_Change_20  per_change_exceeding  \n",
       "0          -1.424262                     0  \n",
       "1          18.581354                     1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e34f7",
   "metadata": {},
   "source": [
    "### Other Company related information: Industry and Sector\n",
    "\n",
    "Below extract the industry and sector of the companies. It could be used for our model, if we decide not to use these variable as features to our model, it can be used for checking the performance of the models. e.g. which industries get the best prediction from our models...\n",
    "\n",
    "There is 6839 tickers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8701b3d",
   "metadata": {},
   "source": [
    "#### prepare unique company ticker df because yahoo finance library takes time to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2145b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['CompanyTicker'] = data2['CompanyTicker'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21df405",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = data2.CompanyTicker.value_counts()\n",
    "ticker_df = ticker_df.reset_index()\n",
    "ticker_df.columns = ['ticker','ticker_cnt']\n",
    "ticker_df['industry'] = ''\n",
    "ticker_df['beta'] = ''\n",
    "ticker_df['sector'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68dd0f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>ticker_cnt</th>\n",
       "      <th>industry</th>\n",
       "      <th>beta</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNNC</td>\n",
       "      <td>29</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DKMR</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIPN</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRCO</td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEPW</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>INRE</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>OPAD</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>LTCH</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>MIR</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>RDW</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6840 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker  ticker_cnt industry beta sector\n",
       "0      CNNC          29                     \n",
       "1      DKMR          21                     \n",
       "2      SIPN          20                     \n",
       "3      SRCO          17                     \n",
       "4      MEPW          15                     \n",
       "...     ...         ...      ...  ...    ...\n",
       "6835   INRE           1                     \n",
       "6836   OPAD           1                     \n",
       "6837   LTCH           1                     \n",
       "6838    MIR           1                     \n",
       "6839    RDW           1                     \n",
       "\n",
       "[6840 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa246643",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/Users/wailunchung/Documents/GitHub/capstone_projectb/tickers_industry.csv'\n",
    "#ticker_df.head(349).to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afef6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/Users/wailunchung/Documents/GitHub/capstone_projectb/tickers_industry.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2e169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTRA\n",
      "6128/6839\n",
      "ACXP\n",
      "6129/6839\n",
      "XMTR\n",
      "6130/6839\n",
      "AOMR\n",
      "6131/6839\n",
      "COUR\n",
      "6132/6839\n",
      "ZIP\n",
      "6133/6839\n",
      "MCW\n",
      "6134/6839\n",
      "TKNO\n",
      "6135/6839\n",
      "ALIT\n",
      "6136/6839\n",
      "UOLI\n",
      "6137/6839\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import yfinance as yf\n",
    "for index, row in ticker_df.iterrows():\n",
    "    if index > 6127:\n",
    "        print(row['ticker'])\n",
    "        print(str(index) + '/6839') \n",
    "        info = yf.Ticker(row['ticker']).info\n",
    "        industry = info.get('industry')\n",
    "        beta = info.get('beta')\n",
    "        sector = info.get('sector')\n",
    "        ticker_df.at[index,'industry'] = industry\n",
    "        ticker_df.at[index,'beta'] = beta\n",
    "        ticker_df.at[index,'sector'] = sector\n",
    "        ticker_df[index:index+1].to_csv(file_name, mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba297fa",
   "metadata": {},
   "source": [
    "## Data Exploratory \n",
    "\n",
    "### Check the number of companies\n",
    "\n",
    "Company Ticker can be one important feature, however, there are 6840 unique tickers from this column. The one-hot encoding method will create too many features that overflow our computing capacity. We consider:\n",
    "\n",
    "1. exclude the ticker column from our model. \n",
    "2. use binary encoding to reduce the number of features, but it creates dependencies between features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9249640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompanyTicker\n",
       "A       9\n",
       "AA      9\n",
       "AAAU    7\n",
       "AAC     3\n",
       "AACI    1\n",
       "       ..\n",
       "ZYME    9\n",
       "ZYNE    9\n",
       "ZYRX    3\n",
       "ZYXI    9\n",
       "ZZLL    9\n",
       "Length: 6840, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.groupby('CompanyTicker').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b73ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6840"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2['CompanyTicker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f59df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data2[\"per_change_exceeding\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5ff06",
   "metadata": {},
   "source": [
    "### Check the stats of numeric columns\n",
    "There is a stock with very high stock price. It is double checked and verified the price is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15a7365e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CompanyCIK</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>1176809.80969</td>\n",
       "      <td>508825.55306</td>\n",
       "      <td>1750.00000</td>\n",
       "      <td>888981.00000</td>\n",
       "      <td>1315257.00000</td>\n",
       "      <td>1580345.00000</td>\n",
       "      <td>1888734.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileDate_ClosingPrice</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>114.32730</td>\n",
       "      <td>5029.73504</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>13.28000</td>\n",
       "      <td>39.25000</td>\n",
       "      <td>435200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileDate_Plus_20_Price</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>114.72741</td>\n",
       "      <td>5042.89659</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.48000</td>\n",
       "      <td>13.40000</td>\n",
       "      <td>39.42000</td>\n",
       "      <td>432469.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_Change_20</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>150.57390</td>\n",
       "      <td>24007.71995</td>\n",
       "      <td>-99.86667</td>\n",
       "      <td>-6.24999</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.99539</td>\n",
       "      <td>5009900.35545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Share_Unit_Value_Raw</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>0.40011</td>\n",
       "      <td>142.47021</td>\n",
       "      <td>-17000.00000</td>\n",
       "      <td>-0.60000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>16801.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_text_length</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>1988.53890</td>\n",
       "      <td>1384.89905</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>1127.00000</td>\n",
       "      <td>1555.00000</td>\n",
       "      <td>2335.00000</td>\n",
       "      <td>14139.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weeknum</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>30.04340</td>\n",
       "      <td>12.40878</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>53.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>2020.13352</td>\n",
       "      <td>0.86110</td>\n",
       "      <td>2019.00000</td>\n",
       "      <td>2019.00000</td>\n",
       "      <td>2020.00000</td>\n",
       "      <td>2021.00000</td>\n",
       "      <td>2022.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_Change_20_mean</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>150.57390</td>\n",
       "      <td>786.19869</td>\n",
       "      <td>-28.28753</td>\n",
       "      <td>-1.75519</td>\n",
       "      <td>0.93324</td>\n",
       "      <td>9.12629</td>\n",
       "      <td>5013.25957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_Change_20_min</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>-69.63613</td>\n",
       "      <td>17.50373</td>\n",
       "      <td>-99.86667</td>\n",
       "      <td>-80.35641</td>\n",
       "      <td>-74.00000</td>\n",
       "      <td>-59.25926</td>\n",
       "      <td>0.10273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_Change_20_max</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>125810.43157</td>\n",
       "      <td>751851.65105</td>\n",
       "      <td>0.10273</td>\n",
       "      <td>155.22936</td>\n",
       "      <td>383.33330</td>\n",
       "      <td>1061.53850</td>\n",
       "      <td>5009900.35545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adj_Pct_Change_20</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23994.84338</td>\n",
       "      <td>-5055.36102</td>\n",
       "      <td>-12.93350</td>\n",
       "      <td>-2.97200</td>\n",
       "      <td>3.31057</td>\n",
       "      <td>5004972.67604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_change_exceeding</th>\n",
       "      <td>44817.00000</td>\n",
       "      <td>0.20410</td>\n",
       "      <td>0.40304</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count           mean           std  \\\n",
       "CompanyCIK              44817.00000  1176809.80969  508825.55306   \n",
       "FileDate_ClosingPrice   44817.00000      114.32730    5029.73504   \n",
       "FileDate_Plus_20_Price  44817.00000      114.72741    5042.89659   \n",
       "Pct_Change_20           44817.00000      150.57390   24007.71995   \n",
       "Share_Unit_Value_Raw    44817.00000        0.40011     142.47021   \n",
       "file_text_length        44817.00000     1988.53890    1384.89905   \n",
       "weeknum                 44817.00000       30.04340      12.40878   \n",
       "year                    44817.00000     2020.13352       0.86110   \n",
       "Pct_Change_20_mean      44817.00000      150.57390     786.19869   \n",
       "Pct_Change_20_min       44817.00000      -69.63613      17.50373   \n",
       "Pct_Change_20_max       44817.00000   125810.43157  751851.65105   \n",
       "adj_Pct_Change_20       44817.00000        0.00000   23994.84338   \n",
       "per_change_exceeding    44817.00000        0.20410       0.40304   \n",
       "\n",
       "                                 min           25%            50%  \\\n",
       "CompanyCIK                1750.00000  888981.00000  1315257.00000   \n",
       "FileDate_ClosingPrice        0.00001       3.50000       13.28000   \n",
       "FileDate_Plus_20_Price       0.00001       3.48000       13.40000   \n",
       "Pct_Change_20              -99.86667      -6.24999        0.00000   \n",
       "Share_Unit_Value_Raw    -17000.00000      -0.60000        0.00000   \n",
       "file_text_length           500.00000    1127.00000     1555.00000   \n",
       "weeknum                      1.00000      19.00000       32.00000   \n",
       "year                      2019.00000    2019.00000     2020.00000   \n",
       "Pct_Change_20_mean         -28.28753      -1.75519        0.93324   \n",
       "Pct_Change_20_min          -99.86667     -80.35641      -74.00000   \n",
       "Pct_Change_20_max            0.10273     155.22936      383.33330   \n",
       "adj_Pct_Change_20        -5055.36102     -12.93350       -2.97200   \n",
       "per_change_exceeding         0.00000       0.00000        0.00000   \n",
       "\n",
       "                                  75%            max  \n",
       "CompanyCIK              1580345.00000  1888734.00000  \n",
       "FileDate_ClosingPrice        39.25000   435200.00000  \n",
       "FileDate_Plus_20_Price       39.42000   432469.00000  \n",
       "Pct_Change_20                 5.99539  5009900.35545  \n",
       "Share_Unit_Value_Raw          0.76000    16801.00000  \n",
       "file_text_length           2335.00000    14139.00000  \n",
       "weeknum                      44.00000       53.00000  \n",
       "year                       2021.00000     2022.00000  \n",
       "Pct_Change_20_mean            9.12629     5013.25957  \n",
       "Pct_Change_20_min           -59.25926        0.10273  \n",
       "Pct_Change_20_max          1061.53850  5009900.35545  \n",
       "adj_Pct_Change_20             3.31057  5004972.67604  \n",
       "per_change_exceeding          0.00000        1.00000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.describe().apply(lambda s: s.apply('{0:.5f}'.format)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63aba5",
   "metadata": {},
   "source": [
    "## Prepare functions to free memory\n",
    "\n",
    "The index sec file is large, as we process the data and create transformed data matrices. More data is created. The following functions help check the memory usage when we delete and garbage collect dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d9af599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_size_fmt(num):\n",
    "    if num<10**3:\n",
    "        return \"{:.2f}{}\".format(num,\"B\")\n",
    "    elif ((num>=10**3)&(num<10**6)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**3),\"KB\")\n",
    "    elif ((num>=10**6)&(num<10**9)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**6),\"MB\")\n",
    "    else:\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**9),\"GB\")\n",
    "\n",
    "def memory_usage():\n",
    "    memory_usage_by_variable=pd.DataFrame({k:sys.getsizeof(v)\\\n",
    "    for (k,v) in globals().items()},index=['Size'])\n",
    "    memory_usage_by_variable=memory_usage_by_variable.T\n",
    "    memory_usage_by_variable=memory_usage_by_variable.sort_values(by='Size',ascending=False).head(10)\n",
    "    memory_usage_by_variable['Size']=memory_usage_by_variable['Size'].apply(lambda x: obj_size_fmt(x))\n",
    "    return memory_usage_by_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b197a20",
   "metadata": {},
   "source": [
    "## Text features\n",
    "\n",
    "### TF-IDF vectorization\n",
    "\n",
    "The Index Sec file contains bag of word phrases. \n",
    "\n",
    "### Check size of matrix\n",
    "\n",
    "#### max_df\n",
    "\"max_df\" is used for removing terms that appear too frequently. There are some phrases that probably all the reports would use, for example, \"report\", \"revenue\", etc. I attempt to set max_df = .98, it ignores terms that appear in more than 95% of the reports. \n",
    "\n",
    "#### min_df\n",
    "Similar to \"max_df\", \"min_df\" is used for removing terms that appear too infrequently. I attempt to set min_df = 0.05, it ignores terms that appear in less than 5% of the reports. \n",
    "\n",
    "#### After setting the limits, the matrix is 44817 x 4632. We have more room to relax the limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84cb8579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 39.9 s, total: 2min 20s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None,\n",
    "    max_df=0.95,     \n",
    "    min_df=0.05\n",
    "    )  \n",
    "\n",
    "K = tfidf.fit_transform(data2['f_text']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c53b368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44817, 4632)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088995c2",
   "metadata": {},
   "source": [
    "Note:\n",
    "- 95% -> 4.6K \n",
    "- 96% -> 5K \n",
    "- 97% -> 7K \n",
    "- 99% -> 20K \n",
    "- 99%, 0.5% -> 37025\n",
    "- 99%, 0.25% -> 65655\n",
    "- 99%, 0.1% ~ 45 doc -> \n",
    "- 99%, 80 -? 87305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369836a",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer Threshold\n",
    "\n",
    "We want to limit our features to be within 100K because of the limited processing power. Since the most frequent term and least frequent term do not produce much value, we exclude the terms that appear in 90% of the reports and terms that appear in less than 70 of our 44817 reports. By setting these threshold, there will be 97629 features. Our input matrix size is (44817, 97629). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92e9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 s, sys: 7.4 s, total: 8.96 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None,\n",
    "    max_df=0.90,     \n",
    "    min_df=70,       \n",
    "    stop_words= None,\n",
    "    strip_accents=None,\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94acab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 45.7 s, total: 2min 30s\n",
      "Wall time: 2min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'various estimate': 95696,\n",
       " 'the result': 85852,\n",
       " 'timely decision': 93155,\n",
       " 'the asset': 73211,\n",
       " 'our property plant': 53178,\n",
       " 'hazardous material': 30132,\n",
       " 'available cash': 11377,\n",
       " 'tax cut': 70920,\n",
       " 'any material loss': 7836,\n",
       " 'november revenue': 45188,\n",
       " 'other party': 48485,\n",
       " 'the company restriction': 75044,\n",
       " 'content impact': 17570,\n",
       " 'net': 42097,\n",
       " 'the nature amount timing': 82000,\n",
       " 'its distribution center': 34462,\n",
       " 'the annual period': 72754,\n",
       " 'certain share': 14698,\n",
       " 'the component': 75414,\n",
       " 'relevant information': 61028,\n",
       " 'material disruption': 39836,\n",
       " 'january': 35577,\n",
       " 'the stock': 87202,\n",
       " 'the company date': 74672,\n",
       " 'transfer': 93870,\n",
       " 'new taxis': 43126,\n",
       " 'filer small reporting company': 26538,\n",
       " 'service cost': 64326,\n",
       " 'total consolidated asset': 93376,\n",
       " 'vi note': 96026,\n",
       " 'million share': 40719,\n",
       " 'the same product': 86300,\n",
       " 'its consideration': 34313,\n",
       " 'the issuer class': 80631,\n",
       " 'market condition': 39453,\n",
       " 'consideration': 17102,\n",
       " 'the balance sheet date': 73473,\n",
       " 'their respective fair value': 89983,\n",
       " 'the majority': 81357,\n",
       " 'fiscal year': 27206,\n",
       " 'reserve': 61567,\n",
       " 'their financial statement': 89578,\n",
       " 'that date': 71643,\n",
       " 'our labor cost': 51861,\n",
       " 'these consolidated financial statement': 90434,\n",
       " 'monitoring': 41101,\n",
       " 'the opening balance': 82674,\n",
       " 'the satisfaction': 86368,\n",
       " 'our credit agreement': 50350,\n",
       " 'the area': 73174,\n",
       " 'the future': 79175,\n",
       " 'the suspension': 87493,\n",
       " 'administrative expense': 2015,\n",
       " 'canadian dollar euro': 13155,\n",
       " 'each item': 22853,\n",
       " 'its customer': 34396,\n",
       " 'outside consultant': 54358,\n",
       " 'the criterion': 76105,\n",
       " 'the new standard': 82253,\n",
       " 'its business operation': 34191,\n",
       " 'our consolidated financial statement': 50168,\n",
       " 'interest income': 33152,\n",
       " 'its financial statement': 34612,\n",
       " 'shareholder equity': 64957,\n",
       " 'common stock repurchase': 16188,\n",
       " 'this award': 91660,\n",
       " 'the form': 78963,\n",
       " 'the benefit': 73615,\n",
       " 'that rate': 71832,\n",
       " 'the matter': 81534,\n",
       " 'end': 24140,\n",
       " 'labor': 36251,\n",
       " 'the excess': 77466,\n",
       " 'such risk factor': 69957,\n",
       " 'the company share': 75076,\n",
       " 'delivery cost': 21029,\n",
       " 'these material': 90806,\n",
       " 'the factor': 77835,\n",
       " 'tax reform': 71019,\n",
       " 'thousand table': 92905,\n",
       " 'the other country': 82899,\n",
       " 'the application': 73067,\n",
       " 'our accrual': 49324,\n",
       " 'all covenant': 2677,\n",
       " 'california': 13120,\n",
       " 'october': 45372,\n",
       " 'prior reporting period': 57746,\n",
       " 'each': 22626,\n",
       " 'the company cash equivalent': 74594,\n",
       " 'the new guidance': 82207,\n",
       " 'level': 37149,\n",
       " 'no outstanding borrowing': 43882,\n",
       " 'environmental law': 24328,\n",
       " 'balance': 11649,\n",
       " 'the come year': 74390,\n",
       " 'remedy': 61135,\n",
       " 'project plan': 58419,\n",
       " 'enactment': 24131,\n",
       " 'hedge program': 30327,\n",
       " 'raw material': 59431,\n",
       " 'grantee': 29778,\n",
       " 'the following table': 78764,\n",
       " 'the netherland': 82176,\n",
       " 'the opinion': 82730,\n",
       " 'terrorism': 71502,\n",
       " 'irs employer incorporation': 33958,\n",
       " 'none item default': 44522,\n",
       " 'april': 10543,\n",
       " 'its charter massachusetts state': 34244,\n",
       " 'service type': 64400,\n",
       " 'tax table': 71049,\n",
       " 'derivative financial instrument': 21242,\n",
       " 'the positive effect': 83791,\n",
       " 'shortterm deferral': 65123,\n",
       " 'strategy': 67721,\n",
       " 'experience': 25671,\n",
       " 'the federal security law': 78008,\n",
       " 'neither the company': 42072,\n",
       " 'the entire agreement': 77166,\n",
       " 'these increase': 90690,\n",
       " 'other income expense net': 47965,\n",
       " 'unemployment level': 94812,\n",
       " 'dividend': 22240,\n",
       " 'share dividend': 64759,\n",
       " 'the nature': 81999,\n",
       " 'variable interest rate': 95586,\n",
       " 'august': 11240,\n",
       " 'magnitude': 38576,\n",
       " 'total': 93296,\n",
       " 'our growth': 51456,\n",
       " 'utility': 95431,\n",
       " 'the second fiscal quarter': 86501,\n",
       " 'site': 66114,\n",
       " 'operating margin': 46403,\n",
       " 'accumulate depreciation': 725,\n",
       " 'organic growth': 46859,\n",
       " 'capital resource': 13342,\n",
       " 'all lease': 2945,\n",
       " 'form 10k': 27754,\n",
       " 'yous dollar': 97498,\n",
       " 'the consolidated financial statement': 75511,\n",
       " 'consolidated statement': 17228,\n",
       " 'the liability': 81001,\n",
       " 'accrue liability': 684,\n",
       " 'order': 46824,\n",
       " 'defer commission': 20774,\n",
       " 'high expense': 30558,\n",
       " 'business level': 12968,\n",
       " 'certain financial asset': 14159,\n",
       " 'our operating cost': 52442,\n",
       " 'contingency': 17751,\n",
       " 'the percentage': 83451,\n",
       " 'content result': 17703,\n",
       " 'contract cost': 18020,\n",
       " 'form': 27753,\n",
       " 'discount': 21979,\n",
       " 'the aggregate number': 72551,\n",
       " 'the effective interest method': 77015,\n",
       " 'the range': 84777,\n",
       " 'the comparability': 75347,\n",
       " 'any subsidiary': 9305,\n",
       " 'all the term': 3713,\n",
       " 'income taxis provision': 31874,\n",
       " 'term': 71430,\n",
       " 'the disclosure requirement': 76704,\n",
       " 'the first quarter': 78314,\n",
       " 'our board': 49593,\n",
       " 'our international subsidiary': 51758,\n",
       " 'not all': 44935,\n",
       " 'november table': 45192,\n",
       " 'continue amount': 17840,\n",
       " 'other expense': 47696,\n",
       " 'comment': 15717,\n",
       " 'the longlived asset': 81228,\n",
       " 'cash dividend': 13525,\n",
       " 'an effect': 4679,\n",
       " 'the power': 83920,\n",
       " 'any further right': 7297,\n",
       " 'derivative net': 21274,\n",
       " 'the margin': 81430,\n",
       " 'our exist customer': 50949,\n",
       " 'tax': 70865,\n",
       " 'net realizable value': 42464,\n",
       " 'its inventory': 34755,\n",
       " 'computation': 16853,\n",
       " 'our fourth fiscal quarter': 51255,\n",
       " 'this act': 91513,\n",
       " 'the standard': 87138,\n",
       " 'the income tax effect': 79984,\n",
       " 'groundwater': 29987,\n",
       " 'our work capital': 54279,\n",
       " 'the commission': 74442,\n",
       " 'functional currency': 28258,\n",
       " 'this classification': 91707,\n",
       " 'notice': 45107,\n",
       " 'parcel': 54812,\n",
       " 'early adoption': 23272,\n",
       " 'the other party': 82947,\n",
       " 'material information': 39864,\n",
       " 'the cumulative effect': 76127,\n",
       " 'all contract': 2651,\n",
       " 'these plan': 90931,\n",
       " 'operating expense cost': 46331,\n",
       " 'the forward contract': 78998,\n",
       " 'the settlement': 86725,\n",
       " 'certain foreign subsidiary': 14192,\n",
       " 'currency': 19395,\n",
       " 'regulatory order': 60575,\n",
       " 'reclassification amount': 59958,\n",
       " 'its income': 34701,\n",
       " 'an annual report': 4435,\n",
       " 'lease expense': 36656,\n",
       " 'hedging activity': 30336,\n",
       " 'the administrator': 72411,\n",
       " 'the company receipt': 75015,\n",
       " 'total liability': 93492,\n",
       " 'the aggregate': 72509,\n",
       " 'yousc section': 97609,\n",
       " 'the employment': 77111,\n",
       " 'operate margin': 46246,\n",
       " 'the accounting': 72124,\n",
       " 'consultant': 17315,\n",
       " 'exist guidance': 25398,\n",
       " 'title united states': 93215,\n",
       " 'august table': 11294,\n",
       " 'area code': 10624,\n",
       " 'the other information': 82926,\n",
       " 'the company manufacturing': 74892,\n",
       " 'the principle': 84266,\n",
       " 'solid growth': 66410,\n",
       " 'such manner': 69358,\n",
       " 'corresponding effect': 18587,\n",
       " 'part item': 54875,\n",
       " 'an entity': 4769,\n",
       " 'prepay expense': 57282,\n",
       " 'environmental protection': 24338,\n",
       " 'note income taxis': 45045,\n",
       " 'quarterly dividend': 59275,\n",
       " 'other intangible asset': 48048,\n",
       " 'our foreign subsidiary': 51228,\n",
       " 'the other quarter': 82965,\n",
       " 'our canadian business': 49773,\n",
       " 'thirdparty application': 91352,\n",
       " 'neither the grantee': 42080,\n",
       " 'commission expense': 15915,\n",
       " 'different assumption': 21506,\n",
       " 'any way': 10014,\n",
       " 'our consolidated balance sheet': 50155,\n",
       " 'the twoclass method': 88277,\n",
       " 'any privacy': 8698,\n",
       " 'the participation': 83250,\n",
       " 'one share': 45828,\n",
       " 'substantial number': 68181,\n",
       " 'require disclosure': 61431,\n",
       " 'all determination': 2721,\n",
       " 'our outstanding share': 52641,\n",
       " 'the acquisition': 72203,\n",
       " 'lawsuit': 36574,\n",
       " 'consolidated financial statement basis': 17183,\n",
       " 'the product': 84393,\n",
       " 'the beginning': 73585,\n",
       " 'exchange': 25101,\n",
       " 'its principal place': 35153,\n",
       " 'the discussion': 76731,\n",
       " 'competitive factor': 16572,\n",
       " 'modify retrospective approach': 41027,\n",
       " 'entity': 24283,\n",
       " 'the conduct': 75455,\n",
       " 'basic income': 11899,\n",
       " 'stifel': 67264,\n",
       " 'future operation': 28763,\n",
       " 'ie lessee': 31344,\n",
       " 'stockbase compensation': 67466,\n",
       " 'healthcare cost': 30237,\n",
       " 'external factor': 25828,\n",
       " 'the current portion': 76236,\n",
       " 'accrue income taxis': 666,\n",
       " 'asset': 10830,\n",
       " 'the rate': 84800,\n",
       " 'estimate': 24755,\n",
       " 'sab': 62593,\n",
       " 'applicable law notice': 10189,\n",
       " 'accumulate other comprehensive loss': 739,\n",
       " 'canada': 13146,\n",
       " 'accounting standard': 571,\n",
       " 'operating segment': 46435,\n",
       " 'future use': 28904,\n",
       " 'transfer price': 93881,\n",
       " 'debt': 20240,\n",
       " 'the exchange rate': 77500,\n",
       " 'revenue table': 62173,\n",
       " 'the company customer contract': 74670,\n",
       " 'pricing term': 57559,\n",
       " 'the follow table': 78661,\n",
       " 'both party': 12560,\n",
       " 'responsibility': 61727,\n",
       " 'human resource': 31226,\n",
       " 'environmental compliance': 24309,\n",
       " 'the rule': 86083,\n",
       " 'the certification date': 74090,\n",
       " 'an increase': 5105,\n",
       " 'healthcare': 30229,\n",
       " 'september': 64010,\n",
       " 'response': 61724,\n",
       " 'the customer location': 76300,\n",
       " 'future equity grant': 28623,\n",
       " 'the table': 87525,\n",
       " 'reference': 60233,\n",
       " 'the canadian dollar': 73916,\n",
       " 'our cash': 49819,\n",
       " 'wide range': 96878,\n",
       " 'our future operating result': 51350,\n",
       " 'our ability': 49306,\n",
       " 'material change': 39807,\n",
       " 'the transfer': 88123,\n",
       " 'guidance': 30053,\n",
       " 'the transfer price': 88130,\n",
       " 'copy': 18374,\n",
       " 'customer': 19791,\n",
       " '2managements discussion': 143,\n",
       " 'total consolidated revenue': 93378,\n",
       " 'other longterm asset': 48214,\n",
       " 'the current fiscal year': 76186,\n",
       " 'all provision': 3320,\n",
       " 'portfolio': 56495,\n",
       " 'raw material work': 59446,\n",
       " 'these discount': 90524,\n",
       " 'retrospective basis': 62019,\n",
       " 'fluctuation': 27444,\n",
       " 'content item control': 17600,\n",
       " 'environmental matter': 24333,\n",
       " 'the tax cut': 87570,\n",
       " 'yous gaap': 97521,\n",
       " 'other service provider': 48874,\n",
       " 'reasonable detail': 59640,\n",
       " 'discussion': 22061,\n",
       " 'soil': 66360,\n",
       " 'investing activity acquisition': 33703,\n",
       " 'significant portion': 65565,\n",
       " 'consolidate statement': 17144,\n",
       " 'our attorney': 49508,\n",
       " 'the vest condition': 88827,\n",
       " 'presentation': 57348,\n",
       " 'other information item': 48013,\n",
       " 'the company attorney': 74547,\n",
       " 'price increase': 57506,\n",
       " 'operating lease': 46355,\n",
       " 'modify retrospective basis': 41028,\n",
       " 'any decrease': 6897,\n",
       " 'applicable legal requirement': 10200,\n",
       " 'rate': 59391,\n",
       " 'all change': 2598,\n",
       " 'environmental liability': 24331,\n",
       " 'operating result': 46428,\n",
       " 'onetime cash payment': 45895,\n",
       " 'assumption': 11002,\n",
       " 'income table': 31812,\n",
       " 'the lessee': 80987,\n",
       " 'share repurchase program': 64861,\n",
       " '13a14a15d14a certification': 58,\n",
       " 'decision': 20619,\n",
       " 'all asset': 2531,\n",
       " 'forward look statement': 27908,\n",
       " 'any offbalance sheet arrangement': 8036,\n",
       " 'whole': 96748,\n",
       " 'amortization expense': 3989,\n",
       " 'revenue recognition policy': 62138,\n",
       " 'our internal source': 51738,\n",
       " 'the service cost component': 86704,\n",
       " 'environmental contingency': 24315,\n",
       " 'the riskfree interest rate': 86046,\n",
       " 'the consequence': 75482,\n",
       " 'contract basis': 18012,\n",
       " 'the change': 74108,\n",
       " 'the uncertainty': 88371,\n",
       " 'total asset': 93308,\n",
       " 'an award': 4640,\n",
       " 'manufacture': 38879,\n",
       " 'estimate cost': 24767,\n",
       " 'shareholder equity consolidate statement': 64962,\n",
       " 'the version': 88822,\n",
       " 'decree': 20686,\n",
       " 'shortterm investment cash equivalent': 65143,\n",
       " 'dual approach': 22522,\n",
       " 'private transaction': 57897,\n",
       " 'estate': 24753,\n",
       " 'the grant date': 79521,\n",
       " 'the transition period': 88145,\n",
       " 'exchange rate fluctuation': 25124,\n",
       " 'payroll cost': 55551,\n",
       " 'the context': 75573,\n",
       " 'the presence': 84054,\n",
       " 'the issuance': 80608,\n",
       " 'such regulation': 69865,\n",
       " 'canadian dollar': 13154,\n",
       " 'the term': 87677,\n",
       " 'interest expense': 33128,\n",
       " 'our capital allocation strategy': 49785,\n",
       " 'our available cash': 49531,\n",
       " 'current asset': 19473,\n",
       " 'return': 62022,\n",
       " 'the vesting': 88844,\n",
       " 'inflation': 32542,\n",
       " 'its compliance': 34300,\n",
       " 'access': 429,\n",
       " 'intangible asset net': 32942,\n",
       " 'their effectiveness': 89497,\n",
       " 'the consolidated balance sheet': 75499,\n",
       " 'seasonality': 63111,\n",
       " 'the necessary information': 82048,\n",
       " 'uncertain tax position': 94636,\n",
       " 'the hedge transaction': 79698,\n",
       " 'each component': 22724,\n",
       " 'our annual report': 49435,\n",
       " 'our competitor': 50108,\n",
       " 'prps': 58805,\n",
       " 'its subsidiary': 35422,\n",
       " 'the adoption': 72414,\n",
       " 'the companys borrowing': 75171,\n",
       " 'satisfaction': 62941,\n",
       " 'the current year': 76273,\n",
       " 'our domestic subsidiary': 50753,\n",
       " 'the measurement period': 81605,\n",
       " 'the recognition': 84922,\n",
       " 'each case': 22700,\n",
       " 'each interim period': 22841,\n",
       " 'demand': 21050,\n",
       " 'wage pressure': 96189,\n",
       " 'its operation': 34967,\n",
       " 'plan': 56293,\n",
       " 'continue operation net income': 17924,\n",
       " 'failure': 25952,\n",
       " 'mitigation measure': 40962,\n",
       " 'our receipt': 53296,\n",
       " 'share price': 64840,\n",
       " 'the risk': 86020,\n",
       " 'shortterm investment cash': 65142,\n",
       " 'you': 97300,\n",
       " 'impairment': 31519,\n",
       " 'those annual period': 92496,\n",
       " 'accounting principle': 544,\n",
       " 'our estimate': 50878,\n",
       " 'any future change': 7311,\n",
       " 'b10q 10q document table': 11595,\n",
       " 'effective income tax rate': 23610,\n",
       " 'gain': 28972,\n",
       " 'the portfolio': 83772,\n",
       " 'merchandise': 40287,\n",
       " 'few exception': 26452,\n",
       " 'arrangement': 10653,\n",
       " 'stockholder': 67539,\n",
       " 'annual period': 5934,\n",
       " 'job': 35653,\n",
       " 'proceed item default': 57969,\n",
       " 'fund': 28262,\n",
       " 'such rule': 69965,\n",
       " 'no right': 44023,\n",
       " 'legal settlement': 36870,\n",
       " 'the third fiscal quarter': 87809,\n",
       " 'the amortization period': 72700,\n",
       " 'such date': 68803,\n",
       " 'the epa': 77238,\n",
       " 'the achievement': 72176,\n",
       " 'disclosure requirement': 21925,\n",
       " 'certain foreign source earning': 14191,\n",
       " 'percentage revenue': 55734,\n",
       " 'the contract': 75665,\n",
       " 'measurement': 40114,\n",
       " 'the amortization': 72696,\n",
       " 'defer income taxis': 20824,\n",
       " 'thirteen week': 91487,\n",
       " 'november': 45155,\n",
       " 'the existence': 77644,\n",
       " 'present value': 57346,\n",
       " 'disposal': 22100,\n",
       " 'net share settlement': 42532,\n",
       " 'additional factual information': 1384,\n",
       " 'an entire fiscal year': 4765,\n",
       " 'future result': 28850,\n",
       " 'either finance': 23717,\n",
       " 'share earning': 64762,\n",
       " 'rebate': 59730,\n",
       " 'high production': 30670,\n",
       " 'one year': 45862,\n",
       " 'the next month': 82285,\n",
       " 'longterm lease': 38160,\n",
       " 'exchange rate': 25118,\n",
       " 'the individual contract': 80132,\n",
       " 'excess': 25067,\n",
       " 'base rate': 11855,\n",
       " 'threshold target': 93035,\n",
       " 'defer financing cost gain': 20809,\n",
       " 'interest': 33087,\n",
       " 'diluted income': 21692,\n",
       " 'actual result': 1030,\n",
       " 'compliance': 16723,\n",
       " 'related service': 60943,\n",
       " 'performance metric': 55774,\n",
       " 'financing activity effect': 26960,\n",
       " 'this account': 91506,\n",
       " 'certain cost': 14000,\n",
       " 'delivery': 21028,\n",
       " 'the life': 81047,\n",
       " 'cash outflow': 13670,\n",
       " 'lease': 36627,\n",
       " 'commitment': 15930,\n",
       " 'this agreement': 91524,\n",
       " 'the assistance': 73261,\n",
       " 'such property': 69763,\n",
       " 'each month': 22904,\n",
       " 'administrative expense depreciation': 2017,\n",
       " 'success': 68282,\n",
       " 'content liquidity': 17617,\n",
       " 'credit': 18958,\n",
       " 'chief executive officer': 14986,\n",
       " 'the owner': 83140,\n",
       " 'reporting segment': 61349,\n",
       " 'the functional currency': 79130,\n",
       " 'the customer table': 76310,\n",
       " 'specific provision': 66801,\n",
       " 'all the right': 3705,\n",
       " '1a risk factor': 103,\n",
       " 'length': 36963,\n",
       " 'applicable table': 10269,\n",
       " 'its construction': 34321,\n",
       " 'implementation': 31561,\n",
       " 'the deferral': 76485,\n",
       " 'the relevant company': 85286,\n",
       " 'the administration': 72366,\n",
       " 'these facility': 90600,\n",
       " 'subsequent event': 67988,\n",
       " 'such financial instrument': 69046,\n",
       " 'august result': 11287,\n",
       " 'content item management discussion': 17606,\n",
       " 'movement': 41504,\n",
       " 'these balance': 90328,\n",
       " 'adjustment': 1974,\n",
       " 'the nonservice component': 82417,\n",
       " 'annual report': 5941,\n",
       " 'amount': 4008,\n",
       " 'notional value': 45123,\n",
       " 'fiscal the company': 27191,\n",
       " 'achievement': 764,\n",
       " 'the company achievement': 74518,\n",
       " 'august cost': 11260,\n",
       " 'onetime transition tax': 45913,\n",
       " 'stock unit': 67446,\n",
       " 'disclosure': 21913,\n",
       " 'the service': 86696,\n",
       " 'the accounting policy': 72141,\n",
       " 'the accompany note': 72097,\n",
       " 'objective': 45303,\n",
       " 'its chief executive officer': 34258,\n",
       " 'cutback': 19976,\n",
       " 'interpretation': 33546,\n",
       " 'high capital expenditure': 30496,\n",
       " 'management discussion': 38767,\n",
       " 'the performance': 83467,\n",
       " 'finish good inventory': 27033,\n",
       " 'only reasonable assurance': 46070,\n",
       " 'file': 26529,\n",
       " 'employment law': 24106,\n",
       " 'risk uncertainty': 62407,\n",
       " 'the forgiveness': 78957,\n",
       " 'these region': 91024,\n",
       " 'this expense': 91859,\n",
       " 'the report amount': 85535,\n",
       " 'the annual rate': 72756,\n",
       " 'other matter': 48277,\n",
       " 'record': 59990,\n",
       " 'all size': 3487,\n",
       " 'income taxis income': 31863,\n",
       " 'the imposition': 79945,\n",
       " 'liquidity': 37627,\n",
       " 'the corresponding period': 75905,\n",
       " 'its outstanding share': 35004,\n",
       " 'every interactive datum file': 24963,\n",
       " 'rightofuse asset': 62315,\n",
       " 'the expect period': 77691,\n",
       " 'critical accounting policy': 19252,\n",
       " 'capital expenditure': 13264,\n",
       " 'senior vice president': 63894,\n",
       " 'other personnel': 48524,\n",
       " 'the determination': 76608,\n",
       " 'its audit financial statement': 34139,\n",
       " 'our business operation': 49710,\n",
       " 'day': 20181,\n",
       " 'our business financial condition': 49670,\n",
       " 'total inventory': 93476,\n",
       " 'our management': 52063,\n",
       " 'its accounting': 34046,\n",
       " 'the transaction price': 88115,\n",
       " 'the meaning': 81595,\n",
       " 'those individual': 92634,\n",
       " 'our plant': 52854,\n",
       " 'evaluation': 24920,\n",
       " 'insurance proceed': 32890,\n",
       " 'future payment': 28783,\n",
       " 'these asset': 90317,\n",
       " 'any dividend payment': 7011,\n",
       " 'no share': 44049,\n",
       " 'all prior agreement': 3291,\n",
       " 'the ultimate impact': 88312,\n",
       " 'any reserve': 8971,\n",
       " 'the past': 83292,\n",
       " 'these fluctuation': 90629,\n",
       " 'the tangible asset': 87530,\n",
       " 'percentage': 55718,\n",
       " 'fair value': 25967,\n",
       " 'the effective tax rate': 77024,\n",
       " 'actual performance': 1024,\n",
       " 'local currency': 37924,\n",
       " 'general economic condition': 29100,\n",
       " 'such management': 69355,\n",
       " 'normal recur adjustment': 44892,\n",
       " 'the massachusetts department': 81506,\n",
       " 'the sec': 86440,\n",
       " 'an opinion': 5553,\n",
       " 'market': 39427,\n",
       " 'the company election': 74712,\n",
       " 'no business': 43371,\n",
       " 'financial point': 26838,\n",
       " 'our business result': 49740,\n",
       " 'measure': 40113,\n",
       " 'improvement': 31675,\n",
       " 'any impairment': 7480,\n",
       " 'addition fluctuation': 1125,\n",
       " 'the negative effect': 82069,\n",
       " 'the gain': 79302,\n",
       " 'lessee': 37125,\n",
       " 'this matter': 92027,\n",
       " 'future period': 28790,\n",
       " 'environmental investigation': 24326,\n",
       " 'these item': 90749,\n",
       " 'other provision': 48639,\n",
       " 'an owner': 5650,\n",
       " 'worker compensation': 97032,\n",
       " 'receivable': 59748,\n",
       " 'this operating segment': 92091,\n",
       " 'shortterm investment': 65139,\n",
       " 'ceo': 13846,\n",
       " 'respectively lessee': 61672,\n",
       " 'uniform': 94928,\n",
       " 'the transaction': 88102,\n",
       " 'the risk factor': 86028,\n",
       " 'sec registrant': 63129,\n",
       " 'the decrease': 76423,\n",
       " 'the withholding amount': 89028,\n",
       " 'no impact': 43652,\n",
       " 'february': 26250,\n",
       " 'tax expense': 70943,\n",
       " 'such law rule': 69277,\n",
       " 'mexico': 40361,\n",
       " 'these contingency': 90439,\n",
       " 'our internal control': 51714,\n",
       " 'the modify retrospective method': 81818,\n",
       " 'the noncurrent portion': 82382,\n",
       " 'the revenue': 85923,\n",
       " 'our financial condition': 51078,\n",
       " 'rise': 62341,\n",
       " 'restricted stock': 61831,\n",
       " 'good': 29461,\n",
       " 'consent order': 17060,\n",
       " 'such factor': 69022,\n",
       " 'our business': 49631,\n",
       " 'cyberattack': 19993,\n",
       " 'annual and interim period': 5881,\n",
       " 'you dollar': 97312,\n",
       " 'other net cash': 48336,\n",
       " 'our employee': 50810,\n",
       " 'certain estimate judgment': 14124,\n",
       " 'our operating result': 52475,\n",
       " 'certification': 14821,\n",
       " 'the program': 84444,\n",
       " 'automation': 11353,\n",
       " 'cumulative basis': 19357,\n",
       " 'our system': 53935,\n",
       " 'the third quarter': 87817,\n",
       " 'resource': 61619,\n",
       " 'its interpretation': 34751,\n",
       " 'amortization': 3984,\n",
       " 'the operating result': 82713,\n",
       " 'income taxis': 31852,\n",
       " 'the settlement agreement': 86726,\n",
       " 'cash equivalent': 13531,\n",
       " 'the natural gas': 81996,\n",
       " 'the receipt': 84879,\n",
       " 'the sale': 86116,\n",
       " 'termination': 71475,\n",
       " 'interim period': 33349,\n",
       " 'item 1a risk factor': 34012,\n",
       " 'their impact': 89629,\n",
       " 'stock option': 67356,\n",
       " 'hand': 30076,\n",
       " 'separate discrete financial information': 63944,\n",
       " 'our business change': 49643,\n",
       " 'the balance': 73468,\n",
       " 'the company revenue': 75049,\n",
       " 'hedge instrument': 30315,\n",
       " 'insurance': 32858,\n",
       " 'subtotal': 68280,\n",
       " 'increase': 31918,\n",
       " 'telephone number date': 71294,\n",
       " 'business': 12848,\n",
       " 'our assumption': 49495,\n",
       " 'disability': 21886,\n",
       " 'privately negotiate transaction': 57902,\n",
       " 'regulatory agency': 60462,\n",
       " 'retain earning': 61969,\n",
       " 'paragraph': 54793,\n",
       " 'legal proceeding': 36853,\n",
       " 'the last few year': 80784,\n",
       " 'our common stock': 50040,\n",
       " 'such subsidiary': 70097,\n",
       " 'our chief executive officer': 49873,\n",
       " 'construct': 17278,\n",
       " 'the average exchange rate': 73413,\n",
       " 'this award agreement': 91661,\n",
       " 'our market': 52114,\n",
       " 'any interim period': 7610,\n",
       " 'our organic growth': 52552,\n",
       " 'potential exposure': 56767,\n",
       " 'the investment performance': 80553,\n",
       " 'the measurement': 81598,\n",
       " 'internal cost': 33385,\n",
       " 'the impairment charge': 79915,\n",
       " 'class common stock': 15172,\n",
       " 'loan': 37735,\n",
       " 'the award': 73450,\n",
       " 'the underlie asset': 88380,\n",
       " 'our more significant judgment': 52206,\n",
       " 'its evaluation': 34526,\n",
       " 'revenue': 62035,\n",
       " 'conformity': 17022,\n",
       " 'equity current liability': 24493,\n",
       " 'its consolidated balance sheet': 34314,\n",
       " 'remediation': 61126,\n",
       " 'our operating income': 52453,\n",
       " 'certain case': 13931,\n",
       " 'the restriction': 85829,\n",
       " 'these amount': 90291,\n",
       " 'the low end': 81276,\n",
       " 'repurchase': 61379,\n",
       " 'these contract': 90440,\n",
       " 'removal': 61166,\n",
       " 'hedge ineffectiveness': 30314,\n",
       " 'the quote market price': 84765,\n",
       " 'other important factor': 47941,\n",
       " 'event': 24932,\n",
       " 'restroom': 61867,\n",
       " 'note business acquisition': 45011,\n",
       " 'the fair value hierarchy': 77861,\n",
       " 'all you': 3775,\n",
       " 'the company employee': 74713,\n",
       " 'deployment': 21104,\n",
       " 'neither the plan': 42085,\n",
       " 'the good interest': 79471,\n",
       " 'other income net income': 47974,\n",
       " 'any loss cost': 7763,\n",
       " 'such law': 69275,\n",
       " 'the tax effect': 87574,\n",
       " 'indemnification': 32240,\n",
       " 'certain provision': 14600,\n",
       " 'the overall impact': 83092,\n",
       " 'the time': 87887,\n",
       " 'its exposure': 34570,\n",
       " 'the currency': 76138,\n",
       " 'our subsidiary': 53897,\n",
       " 'condition': 16943,\n",
       " 'the accompanying consolidate statement': 72106,\n",
       " 'other income net': 47972,\n",
       " 'share calculation': 64685,\n",
       " 'the purpose': 84704,\n",
       " 'the company consolidated revenue': 74635,\n",
       " 'the control': 75742,\n",
       " 'reduction': 60209,\n",
       " 'our consolidated revenue': 50187,\n",
       " 'the impact': 79903,\n",
       " 'reimbursement': 60627,\n",
       " 'each restrict stock unit': 23081,\n",
       " 'an adjustment': 4223,\n",
       " 'the new revenue guidance': 82247,\n",
       " 'component': 16756,\n",
       " 'our effectiveness': 50799,\n",
       " 'the interim period': 80439,\n",
       " 'the report': 85534,\n",
       " 'conjunction': 17032,\n",
       " 'law': 36513,\n",
       " 'any modification': 7902,\n",
       " 'update guidance': 95287,\n",
       " 'the primary source': 84197,\n",
       " 'loss': 38215,\n",
       " 'quarter': 59255,\n",
       " 'such result': 69939,\n",
       " 'the yous dollar': 89167,\n",
       " 'any time': 9852,\n",
       " 'the segment': 86612,\n",
       " 'this new guidance': 92067,\n",
       " 'our sale': 53558,\n",
       " 'table': 70767,\n",
       " 'provisional estimate': 58787,\n",
       " 'the time period': 87902,\n",
       " 'august item unregistered sale': 11275,\n",
       " 'participate security': 54969,\n",
       " 'period cash equivalent': 55831,\n",
       " 'revenue selling': 62154,\n",
       " 'the inflation rate': 80164,\n",
       " 'no assurance': 43348,\n",
       " 'these good': 90659,\n",
       " 'its intangible asset': 34729,\n",
       " 'the increase': 79997,\n",
       " 'the follow material': 78560,\n",
       " 'restricted stock unit': 61842,\n",
       " 'such other address': 69500,\n",
       " 'bex311 exhibit certification': 12085,\n",
       " 'other commercial commitment': 47283,\n",
       " 'performance': 55748,\n",
       " 'certain work': 14806,\n",
       " 'diversity': 22233,\n",
       " 'each site': 23115,\n",
       " 'those cost': 92544,\n",
       " 'the conversion': 75765,\n",
       " 'bex101': 12056,\n",
       " 'similar event': 65798,\n",
       " 'other law': 48140,\n",
       " 'our contractual obligation': 50249,\n",
       " 'the timing manner price': 87929,\n",
       " 'cash payment': 13672,\n",
       " 'operate activity depreciation amortization': 46174,\n",
       " 'third party': 91275,\n",
       " 'our other income expense': 52581,\n",
       " 'range': 59348,\n",
       " 'disruption': 22130,\n",
       " 'price': 57487,\n",
       " 'any repurchase': 8946,\n",
       " 'our revenue growth': 53499,\n",
       " 'the relevant information': 85310,\n",
       " 'the company revenue recognition': 75050,\n",
       " 'those good': 92619,\n",
       " 'syndicate': 70718,\n",
       " 'award': 11575,\n",
       " 'point': 56403,\n",
       " 'the safe harbor': 86096,\n",
       " 'our consideration': 50153,\n",
       " 'the likelihood': 81062,\n",
       " 'such liability': 69315,\n",
       " 'contingent asset': 17797,\n",
       " 'the fair value': 77850,\n",
       " 'date': 20086,\n",
       " 'section chapter': 63357,\n",
       " 'great than month': 29878,\n",
       " 'either case': 23701,\n",
       " 'employment': 24088,\n",
       " 'the anticipate period': 72791,\n",
       " 'the quarter': 84744,\n",
       " 'an escrow account': 4830,\n",
       " 'the value': 88755,\n",
       " 'such fiscal year': 69058,\n",
       " 'collective bargaining agreement': 15653,\n",
       " 'significant change': 65327,\n",
       " 'customer location': 19889,\n",
       " 'the recognition measurement presentation': 84924,\n",
       " 'the extent': 77782,\n",
       " 'outstanding letter': 54489,\n",
       " 'the good': 79458,\n",
       " 'other postretirement': 48554,\n",
       " 'these estimate': 90569,\n",
       " 'land': 36305,\n",
       " 'report': 61302,\n",
       " 'the united kingdom': 88553,\n",
       " 'the next calendar year': 82270,\n",
       " 'no event': 43554,\n",
       " 'bex312 exhibit certification': 12097,\n",
       " 'operating income': 46350,\n",
       " 'its ability': 34039,\n",
       " 'the actual rate': 72273,\n",
       " 'payment': 55459,\n",
       " 'content item': 17599,\n",
       " 'the consent decree': 75479,\n",
       " 'the number': 82500,\n",
       " 'the prior year': 84313,\n",
       " 'view': 96050,\n",
       " 'basis point': 11925,\n",
       " 'their classification lease': 89359,\n",
       " 'contract': 17999,\n",
       " 'any': 6212,\n",
       " 'our corporate office': 50321,\n",
       " 'the companys board': 75170,\n",
       " 'the timing': 87922,\n",
       " 'the early comparative period': 76910,\n",
       " 'our customer': 50523,\n",
       " 'asc income taxis': 10751,\n",
       " 'our vehicle': 54238,\n",
       " 'the computation': 75424,\n",
       " 'certain aspect': 13898,\n",
       " 'chief financial officer certification': 14992,\n",
       " 'consolidated financial statement': 17182,\n",
       " 'penalty': 55607,\n",
       " 'employer': 24081,\n",
       " 'area': 10623,\n",
       " 'the fasb': 77878,\n",
       " 'certain eligible employee': 14102,\n",
       " 'an effective interest method': 4684,\n",
       " 'exchange act rule 13a15f': 25105,\n",
       " 'our dependence': 50639,\n",
       " 'inflation rate': 32548,\n",
       " 'any loss': 7761,\n",
       " 'month': 41116,\n",
       " 'the maximum number': 81570,\n",
       " 'exercise': 25265,\n",
       " 'these factor': 90602,\n",
       " 'defer income taxis change': 20826,\n",
       " 'claim': 15119,\n",
       " 'investigation': 33677,\n",
       " 'adoption': 2074,\n",
       " 'straightline basis': 67658,\n",
       " 'the company manufacturing facility': 74893,\n",
       " 'march': 39098,\n",
       " 'other factor': 47728,\n",
       " 'fair statement': 25964,\n",
       " 'the selling shareholder': 86635,\n",
       " 'example': 25040,\n",
       " 'common stock': 16096,\n",
       " 'prior year': 57772,\n",
       " 'an integral part': 5327,\n",
       " 'net periodic benefit cost': 42434,\n",
       " 'stock': 67275,\n",
       " 'the good estimate': 79461,\n",
       " 'cad': 13103,\n",
       " 'energy price': 24187,\n",
       " 'the party': 83283,\n",
       " 'our current expectation': 50434,\n",
       " 'the restricted stock unit': 85826,\n",
       " 'the relevant fact': 85301,\n",
       " 'the address': 72340,\n",
       " 'tax law': 70967,\n",
       " 'common share': 16018,\n",
       " 'beginning': 11976,\n",
       " 'management judgment': 38790,\n",
       " 'any material impact': 7823,\n",
       " 'the expense': 77733,\n",
       " 'the yous treasury': 89227,\n",
       " 'different meaning': 21565,\n",
       " 'asc': 10712,\n",
       " 'net increase': 42285,\n",
       " 'the consideration': 75485,\n",
       " 'interest accretion': 33088,\n",
       " 'europe': 24889,\n",
       " 'the entire board': 77172,\n",
       " 'noncash item': 44366,\n",
       " 'exchange rate change': 25119,\n",
       " 'federal income tax purpose': 26358,\n",
       " 'the financial statement': 78195,\n",
       " 'existence': 25515,\n",
       " 'the share repurchase program': 86780,\n",
       " 'our estimate cost': 50881,\n",
       " 'our election': 50803,\n",
       " 'the right': 85992,\n",
       " 'the united states canada': 88569,\n",
       " 'this consideration': 91747,\n",
       " 'more information': 41261,\n",
       " 'international market': 33486,\n",
       " 'no': 43274,\n",
       " 'such claim': 68650,\n",
       " 'our disclosure control': 50715,\n",
       " 'the general asset': 79329,\n",
       " 'the only risk': 82660,\n",
       " 'respectively table': 61708,\n",
       " 'current accounting guidance': 19437,\n",
       " 'no obligation': 43823,\n",
       " 'the supervision': 87456,\n",
       " 'the customer': 76290,\n",
       " 'inventory': 33597,\n",
       " 'commission cost': 15914,\n",
       " 'environmental condition': 24312,\n",
       " 'administrative cost': 2010,\n",
       " 'exist customer': 25380,\n",
       " 'their level': 89695,\n",
       " 'approximately million table': 10488,\n",
       " 'income tax expense': 31826,\n",
       " 'the interest rate': 80410,\n",
       " 'the desire control objective': 76593,\n",
       " 'litigation regulatory investigation': 37694,\n",
       " 'recent accounting pronouncement': 59868,\n",
       " 'the aggregate amount': 72511,\n",
       " 'such facility': 69020,\n",
       " 'startup': 67079,\n",
       " 'the grantee': 79534,\n",
       " 'account': 460,\n",
       " 'the performance criterion': 83471,\n",
       " 'this opportunity': 92094,\n",
       " 'an annuity': 4444,\n",
       " 'yes no indicate': 97285,\n",
       " 'benefit': 12025,\n",
       " 'intend': 33019,\n",
       " 'significant reversal': 65605,\n",
       " 'the special committee': 87028,\n",
       " 'our compliance': 50125,\n",
       " 'circumstance': 15057,\n",
       " 'material labor': 39874,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf.fit(data2[\"f_text\"])\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7973ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 16.7 s, total: 1min 33s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_1 = tfidf.transform(data2[\"f_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85049df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44817, 97629)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce9e82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 17.2 s, total: 27.5 s\n",
      "Wall time: 45.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X0 = vector_1.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ece64b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44817, 97629)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418e3bd",
   "metadata": {},
   "source": [
    "#### Convert Matrix to Compressed Sparse Row Matrix\n",
    "Since the matrix is sparse, it is wasteful to store the zero elements. CSR breaks down the data frame for fitting into RAM, so data can easily fit in RAM. Performing operations using only non-zero values of the sparse matrix can greatly increase execution speed of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac141591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 1min 16s, total: 2min 25s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from scipy import sparse\n",
    "X = csr_matrix(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b792dc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44817, 97629)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eee7f9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data2</th>\n",
       "      <td>806.67MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_20</th>\n",
       "      <td>163.84MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_12</th>\n",
       "      <td>717.27KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>350.24KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_11</th>\n",
       "      <td>38.38KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_15</th>\n",
       "      <td>8.22KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearweek_average</th>\n",
       "      <td>6.82KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer</th>\n",
       "      <td>1.96KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>1.04KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSprop</th>\n",
       "      <td>1.04KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Size\n",
       "data2             806.67MB\n",
       "_20               163.84MB\n",
       "_12               717.27KB\n",
       "y                 350.24KB\n",
       "_11                38.38KB\n",
       "_15                 8.22KB\n",
       "yearweek_average    6.82KB\n",
       "TfidfVectorizer     1.96KB\n",
       "StandardScaler      1.04KB\n",
       "RMSprop             1.04KB"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e398f6",
   "metadata": {},
   "source": [
    "#### Clear memory \n",
    "The data is extracted and ready to be modeled. The original dataframe are deleted and cleared to free up some memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bbb0a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 3min 24s, total: 3min 39s\n",
      "Wall time: 8min 59s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_20</th>\n",
       "      <td>163.84MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_</th>\n",
       "      <td>1.60MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_30</th>\n",
       "      <td>1.60MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker_df</th>\n",
       "      <td>1.60MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_12</th>\n",
       "      <td>717.27KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>350.24KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_11</th>\n",
       "      <td>38.38KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_15</th>\n",
       "      <td>8.22KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearweek_average</th>\n",
       "      <td>6.82KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer</th>\n",
       "      <td>1.96KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Size\n",
       "_20               163.84MB\n",
       "_                   1.60MB\n",
       "_30                 1.60MB\n",
       "ticker_df           1.60MB\n",
       "_12               717.27KB\n",
       "y                 350.24KB\n",
       "_11                38.38KB\n",
       "_15                 8.22KB\n",
       "yearweek_average    6.82KB\n",
       "TfidfVectorizer     1.96KB"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "del data2 \n",
    "#del vector_2\n",
    "gc.collect()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129ceff",
   "metadata": {},
   "source": [
    "## Non text features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3d670",
   "metadata": {},
   "source": [
    "### Prepare non-text features\n",
    "\n",
    "We review some of the non-text attributes and see if they produce value to be the features to our model. \n",
    "* Report type: we only have 10-Q reports\n",
    "* Report quarter: it may produce some value to the model. \n",
    "* Year of the report: it provides the time information, however, the data is only collected from 2019 to 2022. It doesn't produce much value to the model. If we use the model to predict stock movement in the future, for example 2023, 2025, it may not help much. \n",
    "* The stock price when the report is filed: it may provide a some information about the size of the company, However, the price do not always reflect the size of a company, because the size and price are also dependent of the number of shares of the stock. \n",
    "* Company ticker: company is an important factor to the stock price, however, the company data is sparse. One-hot encoding for over 6000 possible values might get out of hand, especially some of the compnay are very rare with only 1 report. This leads to the problem of “sparsity” with a huge matrix and almost every value is zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333dc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_non_text_features = data2[['FileType','SecFileName','CompanyTicker','FileDate_ClosingPrice','FileDate']]\n",
    "df_non_text_features = df_non_text_features.reset_index(drop=True)\n",
    "df_non_text_features[\"SecFileName\"] = df_non_text_features[\"SecFileName\"].str.slice(5, 9)\n",
    "df_non_text_features[\"Year\"] = df_non_text_features[\"FileDate\"].dt.year\n",
    "df_non_text_features = df_non_text_features.drop(columns = ['FileDate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d457960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_text_features.describe().apply(lambda s: s.apply('{0:.5f}'.format)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_text_features.groupby('SecFileName').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f063c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_text_features.groupby('FileType').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use on hot encoding\n",
    "# df_non_text_features = pd.get_dummies(df_non_text_features, columns=['FileType','SecFileName','CompanyTicker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "del data2\n",
    "gc.collect()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43fca9",
   "metadata": {},
   "source": [
    "### Encode categorical columns (reserved if non-text features will be used) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['SecFileName','CompanyTicker']);\n",
    "# transform the data \n",
    "data_binary = encoder.fit_transform(df_non_text_features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa65058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize = [\"FileDate_ClosingPrice\",\"Year\"]\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldex = data_binary.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normdf = pd.DataFrame(std.fit_transform(data_binary),columns=data_binary.columns).set_index(alldex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_text_features = csr_matrix(normdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e7b2f",
   "metadata": {},
   "source": [
    "### Stacking the text features and non-text features (reserved if non-text features will be used) \n",
    "\n",
    "Below is the code to stack the text features and non-text features. After reviewing the non-text features, we determined the information from the non-text features is relatively small and stacking the sparse matrix of the text features would also minimize the learning we can get from the non-text features. We decide to only use the text features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c112b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Sparse Matrix..\")\n",
    "# Sparse Matrix\n",
    "#train_features = hstack([\n",
    "#    X,\n",
    "#    non_text_features], 'csr'\n",
    "#)\n",
    "#del train_word_features, train_char_features\n",
    "#print(\"train shape: {} rows, {}\".format(*train_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e299d",
   "metadata": {},
   "source": [
    "### Clear duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "del df_non_text_features\n",
    "del data_binary\n",
    "del alldex\n",
    "del normdf\n",
    "del non_text_features\n",
    "gc.collect()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af301b",
   "metadata": {},
   "source": [
    "## Prepare train and test set for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "867ae209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  35854 and its shape :  (35854, 97629)\n",
      "Size of training labels:  35854 and its shape :  (35854,)\n",
      "Size of test data:  8963 and its shape :  (8963, 97629)\n",
      "Size of test labels:  8963 and its shape :  (8963,)\n",
      "CPU times: user 1.31 s, sys: 3.19 s, total: 4.5 s\n",
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits= 5,shuffle=True,random_state=42)\n",
    "\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train = X[train] \n",
    "    X_test  = X[test] \n",
    "    y_train = y[train]\n",
    "    y_test  = y[test] \n",
    "    \n",
    "print('Size of training data: ', X_train.shape[0], 'and its shape : ', X_train.shape)\n",
    "print('Size of training labels: ', len(y_train), 'and its shape : ', y_train.shape)\n",
    "print('Size of test data: ', X_test.shape[0], 'and its shape : ', X_test.shape)\n",
    "print('Size of test labels: ', len(y_test), 'and its shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a4167",
   "metadata": {},
   "source": [
    "## Model: Traditional Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d471a0a",
   "metadata": {},
   "source": [
    "### Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03ebcd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc Score:  0.5365273535172462\n",
      "CPU times: user 44.3 s, sys: 1.06 s, total: 45.4 s\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "loss = []\n",
    "lr = LogisticRegression(solver=\"sag\", max_iter=100)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Auc Score: \",np.mean(cross_val_score(lr, X_train, y_train, cv=3, scoring='roc_auc')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b889d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297744a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities = model.predict(X_test)\n",
    "#predictions = [float(np.round(x)) for x in probabilities]\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68440ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7123   11]\n",
      " [1808   21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "febe7c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      7134\n",
      "           1       0.66      0.01      0.02      1829\n",
      "\n",
      "    accuracy                           0.80      8963\n",
      "   macro avg       0.73      0.50      0.45      8963\n",
      "weighted avg       0.77      0.80      0.71      8963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c561d",
   "metadata": {},
   "source": [
    "### Model: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e97a2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc Score:  0.5417877396071421\n",
      "CPU times: user 10min 8s, sys: 30.3 s, total: 10min 38s\n",
      "Wall time: 11min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Auc Score: \",np.mean(cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "220d731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76b73022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5175 1325]\n",
      " [1841  622]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29debec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      6500\n",
      "           1       0.32      0.25      0.28      2463\n",
      "\n",
      "    accuracy                           0.65      8963\n",
      "   macro avg       0.53      0.52      0.52      8963\n",
      "weighted avg       0.62      0.65      0.63      8963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e706b6c",
   "metadata": {},
   "source": [
    "### Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ba7150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc Score:  0.5449668874651226\n",
      "CPU times: user 3min 26s, sys: 6.58 s, total: 3min 33s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=20, n_estimators=150, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Auc Score: \",np.mean(cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c2dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c6ce7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6473   27]\n",
      " [2439   24]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17454d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      6500\n",
      "           1       0.47      0.01      0.02      2463\n",
      "\n",
      "    accuracy                           0.72      8963\n",
      "   macro avg       0.60      0.50      0.43      8963\n",
      "weighted avg       0.66      0.72      0.61      8963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d3b35",
   "metadata": {},
   "source": [
    "### Model: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52493718",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:416\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:447\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimum of desired feature range must be smaller than maximum. Got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(feature_range)\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    453\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    454\u001b[0m     X,\n\u001b[1;32m    455\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    459\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead."
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a12fa1ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaled_X_train' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(scaled_X_train, y_train)\n",
    "print(\"Auc Score: \",np.mean(cross_val_score(clf, scaled_X_train, y_train, cv=3, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87340b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5857502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6473   27]\n",
      " [2439   24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "682543b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      6500\n",
      "           1       0.47      0.01      0.02      2463\n",
      "\n",
      "    accuracy                           0.72      8963\n",
      "   macro avg       0.60      0.50      0.43      8963\n",
      "weighted avg       0.66      0.72      0.61      8963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54db8a",
   "metadata": {},
   "source": [
    "### Model: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19521971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc Score:  0.548101224011268\n",
      "CPU times: user 6.1 s, sys: 1.8 s, total: 7.9 s\n",
      "Wall time: 9.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42)\n",
    "clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "print(\"Auc Score: \",np.mean(cross_val_score(clf_svm, X_train, y_train, cv=3, scoring='roc_auc')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8818905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c1a6d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6500    0]\n",
      " [2463    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "406940d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      6500\n",
      "           1       0.00      0.00      0.00      2463\n",
      "\n",
      "    accuracy                           0.73      8963\n",
      "   macro avg       0.36      0.50      0.42      8963\n",
      "weighted avg       0.53      0.73      0.61      8963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce5410",
   "metadata": {},
   "source": [
    "## Model Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987158e3",
   "metadata": {},
   "source": [
    "### Model ANN-a: Neural Network ANN 1 layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717ef20",
   "metadata": {},
   "source": [
    "#### model parameters\n",
    "- node: 64\n",
    "- learning rate = 0.001 (default)\n",
    "- layer 1\n",
    "- dropout = 0 (default) \n",
    "- batch size = 32 \n",
    "- epoch = 8 \n",
    "\n",
    "#### Result: \n",
    "1st epoch, 72.53%, 72.6%\n",
    "overfitting problem after 2nd epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71208b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 02:08:57.537797: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                6248320   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,248,385\n",
      "Trainable params: 6,248,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 211 ms, sys: 506 ms, total: 717 ms\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=97629))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc31d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1121/1121 [==============================] - 110s 94ms/step - loss: 0.5008 - accuracy: 0.7957 - val_loss: 0.4929 - val_accuracy: 0.7965\n",
      "Epoch 2/8\n",
      "1121/1121 [==============================] - 100s 89ms/step - loss: 0.4403 - accuracy: 0.7993 - val_loss: 0.5159 - val_accuracy: 0.7786\n",
      "Epoch 3/8\n",
      "1121/1121 [==============================] - 101s 90ms/step - loss: 0.3701 - accuracy: 0.8239 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 4/8\n",
      "1121/1121 [==============================] - 89s 79ms/step - loss: 0.2987 - accuracy: 0.8585 - val_loss: 0.6799 - val_accuracy: 0.7313\n",
      "Epoch 5/8\n",
      "1121/1121 [==============================] - 86s 77ms/step - loss: 0.2440 - accuracy: 0.8849 - val_loss: 0.7888 - val_accuracy: 0.7166\n",
      "Epoch 6/8\n",
      "1121/1121 [==============================] - 90s 81ms/step - loss: 0.2005 - accuracy: 0.9074 - val_loss: 0.9452 - val_accuracy: 0.7344\n",
      "Epoch 7/8\n",
      "1121/1121 [==============================] - 113s 101ms/step - loss: 0.1702 - accuracy: 0.9225 - val_loss: 1.0264 - val_accuracy: 0.7159\n",
      "Epoch 8/8\n",
      "1121/1121 [==============================] - 123s 109ms/step - loss: 0.1446 - accuracy: 0.9341 - val_loss: 1.1533 - val_accuracy: 0.7159\n",
      "CPU times: user 19min 41s, sys: 6min 58s, total: 26min 40s\n",
      "Wall time: 13min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3405b",
   "metadata": {},
   "source": [
    "### Model ANN-b: Neural Network ANN 1 layer with dropout 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2742345",
   "metadata": {},
   "source": [
    "#### model parameters\n",
    "- node: 64\n",
    "- learning rate = 0.001 (default)\n",
    "- layer 1\n",
    "- dropout = 0.8 <---\n",
    "- batch size = 32 \n",
    "- epoch = 8 + 8\n",
    "\n",
    "#### Result: \n",
    "* 3th epoch, 72.82%, 72.58%\n",
    "* there is still an overfiting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b298cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                6248320   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,248,385\n",
      "Trainable params: 6,248,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 126 ms, sys: 90.2 ms, total: 216 ms\n",
      "Wall time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=97629))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90edde34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1121/1121 [==============================] - 107s 95ms/step - loss: 0.5195 - accuracy: 0.7957 - val_loss: 0.4957 - val_accuracy: 0.7959\n",
      "Epoch 2/8\n",
      "1121/1121 [==============================] - 104s 93ms/step - loss: 0.4874 - accuracy: 0.7959 - val_loss: 0.4947 - val_accuracy: 0.7959\n",
      "Epoch 3/8\n",
      "1121/1121 [==============================] - 104s 93ms/step - loss: 0.4665 - accuracy: 0.7959 - val_loss: 0.4970 - val_accuracy: 0.7959\n",
      "Epoch 4/8\n",
      "1121/1121 [==============================] - 105s 94ms/step - loss: 0.4484 - accuracy: 0.7959 - val_loss: 0.5051 - val_accuracy: 0.7959\n",
      "Epoch 5/8\n",
      "1121/1121 [==============================] - 108s 96ms/step - loss: 0.4328 - accuracy: 0.7959 - val_loss: 0.5117 - val_accuracy: 0.7959\n",
      "Epoch 6/8\n",
      "1121/1121 [==============================] - 106s 94ms/step - loss: 0.4187 - accuracy: 0.8016 - val_loss: 0.5268 - val_accuracy: 0.7966\n",
      "Epoch 7/8\n",
      "1121/1121 [==============================] - 108s 96ms/step - loss: 0.4053 - accuracy: 0.8079 - val_loss: 0.5479 - val_accuracy: 0.7929\n",
      "Epoch 8/8\n",
      "1121/1121 [==============================] - 111s 99ms/step - loss: 0.3961 - accuracy: 0.8147 - val_loss: 0.5604 - val_accuracy: 0.7860\n",
      "CPU times: user 19min 57s, sys: 7min 6s, total: 27min 4s\n",
      "Wall time: 14min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd338b",
   "metadata": {},
   "source": [
    "#### dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccf902a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                6248320   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,248,385\n",
      "Trainable params: 6,248,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 133 ms, sys: 77 ms, total: 210 ms\n",
      "Wall time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=97629))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "150b744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1121/1121 [==============================] - 108s 95ms/step - loss: 0.5023 - accuracy: 0.7958 - val_loss: 0.4933 - val_accuracy: 0.7959\n",
      "Epoch 2/8\n",
      "1121/1121 [==============================] - 105s 94ms/step - loss: 0.4402 - accuracy: 0.7970 - val_loss: 0.5105 - val_accuracy: 0.7965\n",
      "Epoch 3/8\n",
      "1121/1121 [==============================] - 138s 123ms/step - loss: 0.3776 - accuracy: 0.8129 - val_loss: 0.5510 - val_accuracy: 0.7511\n",
      "Epoch 4/8\n",
      "1121/1121 [==============================] - 157s 140ms/step - loss: 0.3202 - accuracy: 0.8428 - val_loss: 0.6461 - val_accuracy: 0.7471\n",
      "Epoch 5/8\n",
      "1121/1121 [==============================] - 153s 137ms/step - loss: 0.2735 - accuracy: 0.8699 - val_loss: 0.7362 - val_accuracy: 0.7409\n",
      "Epoch 6/8\n",
      "1121/1121 [==============================] - 156s 139ms/step - loss: 0.2356 - accuracy: 0.8927 - val_loss: 0.8101 - val_accuracy: 0.7240\n",
      "Epoch 7/8\n",
      "1121/1121 [==============================] - 154s 137ms/step - loss: 0.2024 - accuracy: 0.9096 - val_loss: 0.8723 - val_accuracy: 0.6953\n",
      "Epoch 8/8\n",
      "1121/1121 [==============================] - 156s 139ms/step - loss: 0.1781 - accuracy: 0.9222 - val_loss: 0.9685 - val_accuracy: 0.7164\n",
      "CPU times: user 25min 23s, sys: 8min 30s, total: 33min 54s\n",
      "Wall time: 18min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dacf010",
   "metadata": {},
   "source": [
    "### higher learning rate \n",
    "higher learning rate does not improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7218437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                6248320   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,248,385\n",
      "Trainable params: 6,248,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 139 ms, sys: 97.8 ms, total: 237 ms\n",
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "learning_rate = 0.005\n",
    "\n",
    "custom_adam = tf.keras.optimizers.Adam(lr=learning_rate) #, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=97629))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da65c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1121/1121 [==============================] - 155s 137ms/step - loss: 0.5016 - accuracy: 0.7957 - val_loss: 0.4919 - val_accuracy: 0.7959\n",
      "Epoch 2/8\n",
      "1121/1121 [==============================] - 155s 138ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7946\n",
      "Epoch 3/8\n",
      "1121/1121 [==============================] - 158s 140ms/step - loss: 0.3628 - accuracy: 0.8198 - val_loss: 0.5851 - val_accuracy: 0.7539\n",
      "Epoch 4/8\n",
      "1121/1121 [==============================] - 158s 141ms/step - loss: 0.2972 - accuracy: 0.8526 - val_loss: 0.6923 - val_accuracy: 0.7319\n",
      "Epoch 5/8\n",
      "1121/1121 [==============================] - 157s 140ms/step - loss: 0.2414 - accuracy: 0.8860 - val_loss: 0.7982 - val_accuracy: 0.6912\n",
      "Epoch 6/8\n",
      "1121/1121 [==============================] - 159s 142ms/step - loss: 0.2026 - accuracy: 0.9070 - val_loss: 0.9559 - val_accuracy: 0.7159\n",
      "Epoch 7/8\n",
      "1121/1121 [==============================] - 155s 138ms/step - loss: 0.1737 - accuracy: 0.9204 - val_loss: 1.0706 - val_accuracy: 0.7279\n",
      "Epoch 8/8\n",
      "1121/1121 [==============================] - 154s 137ms/step - loss: 0.1467 - accuracy: 0.9337 - val_loss: 1.2080 - val_accuracy: 0.7207\n",
      "CPU times: user 27min 54s, sys: 9min 14s, total: 37min 9s\n",
      "Wall time: 20min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d07de2",
   "metadata": {},
   "source": [
    "#### add 1 layer with .5 drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "875d9183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 64)                6248320   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,250,433\n",
      "Trainable params: 6,250,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 159 ms, sys: 95.5 ms, total: 254 ms\n",
      "Wall time: 235 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=97629))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "262c046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1121/1121 [==============================] - 156s 138ms/step - loss: 0.5135 - accuracy: 0.7958 - val_loss: 0.4929 - val_accuracy: 0.7959\n",
      "Epoch 2/8\n",
      "1121/1121 [==============================] - 159s 142ms/step - loss: 0.4731 - accuracy: 0.7959 - val_loss: 0.4996 - val_accuracy: 0.7959\n",
      "Epoch 3/8\n",
      "1121/1121 [==============================] - 158s 141ms/step - loss: 0.4308 - accuracy: 0.7976 - val_loss: 0.5224 - val_accuracy: 0.7908\n",
      "Epoch 4/8\n",
      "1121/1121 [==============================] - 158s 141ms/step - loss: 0.3939 - accuracy: 0.8154 - val_loss: 0.5680 - val_accuracy: 0.7705\n",
      "Epoch 5/8\n",
      "1121/1121 [==============================] - 158s 141ms/step - loss: 0.3591 - accuracy: 0.8313 - val_loss: 0.5963 - val_accuracy: 0.7538\n",
      "Epoch 6/8\n",
      "1121/1121 [==============================] - 158s 141ms/step - loss: 0.3301 - accuracy: 0.8466 - val_loss: 0.6571 - val_accuracy: 0.7292\n",
      "Epoch 7/8\n",
      "1121/1121 [==============================] - 161s 144ms/step - loss: 0.3086 - accuracy: 0.8595 - val_loss: 0.7063 - val_accuracy: 0.7348\n",
      "Epoch 8/8\n",
      "1121/1121 [==============================] - 157s 140ms/step - loss: 0.2822 - accuracy: 0.8742 - val_loss: 0.7964 - val_accuracy: 0.7414\n",
      "CPU times: user 27min 26s, sys: 8min 56s, total: 36min 23s\n",
      "Wall time: 21min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903aa661",
   "metadata": {},
   "source": [
    "### Model: Deeper neural network with more neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55be99a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 1000)              97630000  \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 50)                25050     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,155,601\n",
      "Trainable params: 98,155,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(122)\n",
    "batch_size = 32\n",
    "nb_epochs = 5\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_dim=97629))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation='relu',input_shape= (97629,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(nb_classes))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31bf5bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1121/1121 [==============================] - 2680s 2s/step - loss: 0.5176 - accuracy: 0.7953 - val_loss: 0.4948 - val_accuracy: 0.7959\n",
      "Epoch 2/5\n",
      "1121/1121 [==============================] - 2657s 2s/step - loss: 0.4754 - accuracy: 0.7958 - val_loss: 0.5020 - val_accuracy: 0.7959\n",
      "Epoch 3/5\n",
      "1121/1121 [==============================] - 2063s 2s/step - loss: 0.4166 - accuracy: 0.8063 - val_loss: 0.5713 - val_accuracy: 0.7942\n",
      "Epoch 4/5\n",
      "1121/1121 [==============================] - 1765s 2s/step - loss: 0.3478 - accuracy: 0.8283 - val_loss: 0.6667 - val_accuracy: 0.7772\n",
      "Epoch 5/5\n",
      "1121/1121 [==============================] - 1770s 2s/step - loss: 0.2869 - accuracy: 0.8587 - val_loss: 0.8012 - val_accuracy: 0.7512\n",
      "CPU times: user 4h 43min 6s, sys: 3h 18min 6s, total: 8h 1min 13s\n",
      "Wall time: 3h 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dba74ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - 172s 153ms/step - loss: 0.2274 - accuracy: 0.9019\n",
      "\n",
      "Loss: 0.23, Accuracy: 90.19%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf129d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 75.12%\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict(X_test)\n",
    "predictions = [float(np.round(x)) for x in probabilities]\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5999d0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6480  654]\n",
      " [1576  253]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18975e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85      7134\n",
      "           1       0.28      0.14      0.18      1829\n",
      "\n",
      "    accuracy                           0.75      8963\n",
      "   macro avg       0.54      0.52      0.52      8963\n",
      "weighted avg       0.70      0.75      0.72      8963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1846d68",
   "metadata": {},
   "source": [
    "note (model with tickers)\n",
    "32, epoch 8,  84.4%, 71.54% best epoch 3 -> 75.1%, 74.5%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08f435",
   "metadata": {},
   "source": [
    "### LSTM (Long Short Term Memory) model\n",
    "The ANN model doesn't seem to do better than logistic regresssion. LSTM maybe another model can be tried. \n",
    "\n",
    "#### LSTM Modeling\n",
    "* Vectorize consumer complaints text, by turning each text into either a sequence of integers or into a vector.\n",
    "* Limit the data set to the top 100,000 words.\n",
    "* Set the max number of words in each reports at 2500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2be09838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5449804 unique tokens.\n",
      "CPU times: user 3min 8s, sys: 27.9 s, total: 3min 36s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 100000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 2500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='', lower=True)\n",
    "tokenizer.fit_on_texts(data2['f_text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241a86a",
   "metadata": {},
   "source": [
    "* Truncate and pad the input sequences so that they are all in the same length for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cc551cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (44817, 2500)\n",
      "CPU times: user 1min 41s, sys: 25.1 s, total: 2min 6s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = tokenizer.texts_to_sequences(data2['f_text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "211bd408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  35854 and its shape :  (35854, 2500)\n",
      "Size of training labels:  35854 and its shape :  (35854,)\n",
      "Size of test data:  8963 and its shape :  (8963, 2500)\n",
      "Size of test labels:  8963 and its shape :  (8963,)\n",
      "CPU times: user 675 ms, sys: 959 ms, total: 1.63 s\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits= 5,shuffle=True,random_state=42)\n",
    "\n",
    "for train, test in cv.split(X,y):\n",
    "    X_train = X[train] \n",
    "    X_test  = X[test] \n",
    "    y_train = y[train]\n",
    "    y_test  = y[test] \n",
    "    \n",
    "print('Size of training data: ', X_train.shape[0], 'and its shape : ', X_train.shape)\n",
    "print('Size of training labels: ', len(y_train), 'and its shape : ', y_train.shape)\n",
    "print('Size of test data: ', X_test.shape[0], 'and its shape : ', X_test.shape)\n",
    "print('Size of test labels: ', len(y_test), 'and its shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda7d1b",
   "metadata": {},
   "source": [
    "* The first layer is the embedded layer that uses 100 length vectors to represent each word.\n",
    "* SpatialDropout1D performs variational dropout in NLP models.\n",
    "* The next layer is the LSTM layer with 100 memory units.\n",
    "* The output layer must create 1 output values.\n",
    "* Activation function is softmax for binary classification.\n",
    "* Because it is a binary classification problem, categorical_crossentropy is used as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47fff994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 2500, 100)         10000000  \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spatia  (None, 2500, 100)        0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,080,501\n",
      "Trainable params: 10,080,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CPU times: user 312 ms, sys: 85.4 ms, total: 397 ms\n",
      "Wall time: 606 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
    "from keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "nb_epochs = 5\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "496611cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1121/1121 [==============================] - 4363s 4s/step - loss: 0.0000e+00 - accuracy: 0.7251 - val_loss: 0.0000e+00 - val_accuracy: 0.7252\n",
      "Epoch 2/5\n",
      "1121/1121 [==============================] - 5817s 5s/step - loss: 0.0000e+00 - accuracy: 0.7253 - val_loss: 0.0000e+00 - val_accuracy: 0.7252\n",
      "Epoch 3/5\n",
      "1121/1121 [==============================] - 4448s 4s/step - loss: 0.0000e+00 - accuracy: 0.7253 - val_loss: 0.0000e+00 - val_accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "1121/1121 [==============================] - 4245s 4s/step - loss: 0.0000e+00 - accuracy: 0.7253 - val_loss: 0.0000e+00 - val_accuracy: 0.7252\n",
      "Epoch 5/5\n",
      "1121/1121 [==============================] - 4843s 4s/step - loss: 0.0000e+00 - accuracy: 0.7253 - val_loss: 0.0000e+00 - val_accuracy: 0.7252\n",
      "CPU times: user 14h 32min 36s, sys: 3h 41min 15s, total: 18h 13min 51s\n",
      "Wall time: 6h 35min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e5b2d",
   "metadata": {},
   "source": [
    "## ########## BELOW are WIP codes ########## ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37528e",
   "metadata": {},
   "source": [
    "### CNN-BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37edef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool]) \n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "preds = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7801d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5ac3",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f772640b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SpatialDropout1D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Embedding(\u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m100\u001b[39m, input_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m97629\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mSpatialDropout1D\u001b[49m(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m100\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, recurrent_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m))\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SpatialDropout1D' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "\n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "\n",
    "max_length = 97629\n",
    "embedding_vector_features=45\n",
    "vocab_size = 97629\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 100, input_length=97629))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16639651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"embedding_4\" (type Embedding).\n    \n    Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"sequential_8/embedding_4/Cast:0\", shape=(None,), dtype=int32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n    \n    Call arguments received:\n      • inputs=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x2dfeb69d0>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/wailunchung/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"embedding_4\" (type Embedding).\n    \n    Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"sequential_8/embedding_4/Cast:0\", shape=(None,), dtype=int32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n    \n    Call arguments received:\n      • inputs=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x2dfeb69d0>\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=nb_epochs,verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 100\n",
    "kernel_size = 3\n",
    "activation = 'relu'\n",
    "input1 = Input(shape=(max_length,))\n",
    "embeddding1 = Embedding(input_dim=97629, \n",
    "                            output_dim=1, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = False)(input1)\n",
    "conv1 = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \n",
    "                   kernel_constraint= MaxNorm( max_value=3, axis=[0,1]))(embeddding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_CNN_BiGRU(filters = 100, kernel_size = 3, activation='relu', \n",
    "                   input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "  \n",
    "    # Channel 1D CNN\n",
    "input1 = Input(shape=(max_length,))\n",
    "embeddding1 = Embedding(input_dim=input_dim, \n",
    "                            output_dim=output_dim, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = False)(input1)\n",
    "    conv1 = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \n",
    "                   kernel_constraint= MaxNorm( max_value=3, axis=[0,1]))(embeddding1)\n",
    "    pool1 = MaxPool1D(pool_size=2, strides=2)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    drop1 = Dropout(0.5)(flat1)\n",
    "    dense1 = Dense(10, activation='relu')(drop1)\n",
    "    drop1 = Dropout(0.5)(dense1)\n",
    "    out1 = Dense(1, activation='sigmoid')(drop1)\n",
    "    \n",
    "    # Channel BiGRU\n",
    "    input2 = Input(shape=(max_length,))\n",
    "    embeddding2 = Embedding(input_dim=input_dim, \n",
    "                            output_dim=output_dim, \n",
    "                            input_length=max_length, \n",
    "                            input_shape=(max_length, ),\n",
    "                            # Assign the embedding weight with word2vec embedding marix\n",
    "                            weights = [emb_matrix],\n",
    "                            # Set the weight to be not trainable (static)\n",
    "                            trainable = False,\n",
    "                            mask_zero=True)(input2)\n",
    "    gru2 = Bidirectional(GRU(64))(embeddding2)\n",
    "    drop2 = Dropout(0.5)(gru2)\n",
    "    out2 = Dense(1, activation='sigmoid')(drop2)\n",
    "    \n",
    "    # Merge\n",
    "    merged = concatenate([out1, out2])\n",
    "    \n",
    "    # Interpretation\n",
    "    outputs = Dense(1, activation='sigmoid')(merged)\n",
    "    model = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile( loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ab307",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot\n",
    "train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc[1], test_acc[1]))\n",
    "# plot training history\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1552709",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(122)\n",
    "nb_classes = 2\n",
    "batch_size = 32\n",
    "nb_epochs = 8\n",
    "learning_rate = 0.01\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,input_shape= (10000,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(nb_classes))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# defining the architecture of this connected neural network\n",
    "\n",
    "def build_fc_model():    \n",
    "    '''defining the model using the Sequential class'''\n",
    "    fc_model = tf.keras.Sequential([\n",
    "      # First define a input layer\n",
    "      tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "      # Defining the activation function for the first fully connected (Dense) layer      \n",
    "      tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),      \n",
    "      # Defining the activation function for the second fully connected (Dense) layer      \n",
    "      tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),     \n",
    "      # Defining the activation function for the third fully connected (Dense) layer      \n",
    "      tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),   \n",
    "      # Defining the second Dense layer to output the classification probabilities\n",
    "      tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, activity_regularizer=tf.keras.regularizers.L2(0.01))       \n",
    "    ])\n",
    "    return fc_model\n",
    "\n",
    "model2 = build_fc_model()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2efa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "history2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=BATCH_SIZE, epochs=EPOCHS,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model2.evaluate(X_train, y_train)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "probabilities = model2.predict(X_test)\n",
    "predictions = [float(numpy.round(x)) for x in probabilities]\n",
    "accuracy = numpy.mean(predictions == y_test)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdcb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f86bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa6563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/Users/wailunchung/Documents/GitHub/Capstone_data/my_model'\n",
    "model.save(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768d8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a1d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feaf452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2846ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d51d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37382224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3812"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

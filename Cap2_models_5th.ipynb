{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84444936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5202f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1830b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca096c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "from collections import Counter\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import category_encoders as ce\n",
    "import sys  #system specific parameters and names\n",
    "import gc   #garbage collector interface\n",
    "import yfinance as yf\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "\n",
    "## tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.regularizers import l2\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1cf62d",
   "metadata": {},
   "source": [
    "## Functions for memory clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24020c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_size_fmt(num):\n",
    "    if num<10**3:\n",
    "        return \"{:.2f}{}\".format(num,\"B\")\n",
    "    elif ((num>=10**3)&(num<10**6)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**3),\"KB\")\n",
    "    elif ((num>=10**6)&(num<10**9)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**6),\"MB\")\n",
    "    else:\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**9),\"GB\")\n",
    "\n",
    "def memory_usage():\n",
    "    memory_usage_by_variable=pd.DataFrame({k:sys.getsizeof(v)\\\n",
    "    for (k,v) in globals().items()},index=['Size'])\n",
    "    memory_usage_by_variable=memory_usage_by_variable.T\n",
    "    memory_usage_by_variable=memory_usage_by_variable.sort_values(by='Size',ascending=False).head(10)\n",
    "    memory_usage_by_variable['Size']=memory_usage_by_variable['Size'].apply(lambda x: obj_size_fmt(x))\n",
    "    return memory_usage_by_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743de48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dey4d\\CapstoneProj\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# the current working directory.\n",
    "currentDirectory = os.getcwd()\n",
    "print(currentDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17fad35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.8 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_in = r'C:\\Users\\dey4d\\CapstoneProj\\index_sec'\n",
    "import pickle as pickle\n",
    "with open(file_in, \"rb\") as fh:\n",
    "    data2 = pickle.load(fh)\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04c5874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyCIK</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileDate</th>\n",
       "      <th>EdgarTextUrl</th>\n",
       "      <th>EdgarHtmlUrl</th>\n",
       "      <th>AccessionNumber</th>\n",
       "      <th>SecFileName</th>\n",
       "      <th>CompanyTicker</th>\n",
       "      <th>FileDate_ClosingPrice</th>\n",
       "      <th>FileDate_Plus_20</th>\n",
       "      <th>FileDate_Plus_20_Price</th>\n",
       "      <th>Pct_Change_20</th>\n",
       "      <th>Share_Unit_Value_Raw</th>\n",
       "      <th>FileName</th>\n",
       "      <th>f_text</th>\n",
       "      <th>file_text_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>717954</td>\n",
       "      <td>UNIFIRST CORP</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>edgar/data/717954/0001284084-19-000002.txt</td>\n",
       "      <td>edgar/data/717954/0001284084-19-000002-index.html</td>\n",
       "      <td>0001284084-19-000002</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>UNF</td>\n",
       "      <td>133.860001</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>136.509995</td>\n",
       "      <td>1.979676</td>\n",
       "      <td>2.649994</td>\n",
       "      <td>717954_0001284084-19-000002.txt</td>\n",
       "      <td>[various estimate, the result, timely decision...</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>1084765</td>\n",
       "      <td>RESOURCES CONNECTION INC</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>edgar/data/1084765/0001193125-19-001543.txt</td>\n",
       "      <td>edgar/data/1084765/0001193125-19-001543-index....</td>\n",
       "      <td>0001193125-19-001543</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>RGP</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>16.590000</td>\n",
       "      <td>21.985292</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>1084765_0001193125-19-001543.txt</td>\n",
       "      <td>[asc topic contract term, limited number, the ...</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CompanyCIK               CompanyName FileType   FileDate  \\\n",
       "FileDate                                                               \n",
       "2019-01-03      717954             UNIFIRST CORP     10-Q 2019-01-03   \n",
       "2019-01-03     1084765  RESOURCES CONNECTION INC     10-Q 2019-01-03   \n",
       "\n",
       "                                           EdgarTextUrl  \\\n",
       "FileDate                                                  \n",
       "2019-01-03   edgar/data/717954/0001284084-19-000002.txt   \n",
       "2019-01-03  edgar/data/1084765/0001193125-19-001543.txt   \n",
       "\n",
       "                                                 EdgarHtmlUrl  \\\n",
       "FileDate                                                        \n",
       "2019-01-03  edgar/data/717954/0001284084-19-000002-index.html   \n",
       "2019-01-03  edgar/data/1084765/0001193125-19-001543-index....   \n",
       "\n",
       "                 AccessionNumber SecFileName CompanyTicker  \\\n",
       "FileDate                                                     \n",
       "2019-01-03  0001284084-19-000002   2019-QTR1           UNF   \n",
       "2019-01-03  0001193125-19-001543   2019-QTR1           RGP   \n",
       "\n",
       "            FileDate_ClosingPrice FileDate_Plus_20  FileDate_Plus_20_Price  \\\n",
       "FileDate                                                                     \n",
       "2019-01-03             133.860001       2019-01-23              136.509995   \n",
       "2019-01-03              13.600000       2019-01-23               16.590000   \n",
       "\n",
       "            Pct_Change_20  Share_Unit_Value_Raw  \\\n",
       "FileDate                                          \n",
       "2019-01-03       1.979676              2.649994   \n",
       "2019-01-03      21.985292              2.990000   \n",
       "\n",
       "                                    FileName  \\\n",
       "FileDate                                       \n",
       "2019-01-03   717954_0001284084-19-000002.txt   \n",
       "2019-01-03  1084765_0001193125-19-001543.txt   \n",
       "\n",
       "                                                       f_text  \\\n",
       "FileDate                                                        \n",
       "2019-01-03  [various estimate, the result, timely decision...   \n",
       "2019-01-03  [asc topic contract term, limited number, the ...   \n",
       "\n",
       "            file_text_length  \n",
       "FileDate                      \n",
       "2019-01-03              1870  \n",
       "2019-01-03              2305  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05472b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45382.000000\n",
       "mean      1968.146137\n",
       "std       1388.282347\n",
       "min         22.000000\n",
       "25%       1112.000000\n",
       "50%       1542.000000\n",
       "75%       2318.000000\n",
       "max      14139.000000\n",
       "Name: file_text_length, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the statistics of file_text_length\n",
    "data2['file_text_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8af9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking only stocks with the filings size (file_text_length) greater than 1000\n",
    "data_filing_size = data2[data2['file_text_length'] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2e07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_filing_size.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277b9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking only stocks with values more than 50\n",
    "data_filingsize_price = data_filing_size[data_filing_size['FileDate_ClosingPrice'] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8216fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 7820 entries, 2019-01-03 to 2022-04-04\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   CompanyCIK              7820 non-null   int64         \n",
      " 1   CompanyName             7820 non-null   object        \n",
      " 2   FileType                7820 non-null   object        \n",
      " 3   FileDate                7820 non-null   datetime64[ns]\n",
      " 4   EdgarTextUrl            7820 non-null   object        \n",
      " 5   EdgarHtmlUrl            7820 non-null   object        \n",
      " 6   AccessionNumber         7820 non-null   object        \n",
      " 7   SecFileName             7820 non-null   object        \n",
      " 8   CompanyTicker           7820 non-null   object        \n",
      " 9   FileDate_ClosingPrice   7820 non-null   float64       \n",
      " 10  FileDate_Plus_20        7820 non-null   datetime64[ns]\n",
      " 11  FileDate_Plus_20_Price  7820 non-null   float64       \n",
      " 12  Pct_Change_20           7820 non-null   float64       \n",
      " 13  Share_Unit_Value_Raw    7820 non-null   float64       \n",
      " 14  FileName                7820 non-null   object        \n",
      " 15  f_text                  7820 non-null   object        \n",
      " 16  file_text_length        7820 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(2), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_filingsize_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c39e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## features besides text to be used in the model\n",
    "df_non_text_features = data_filingsize_price.drop(columns = ['CompanyCIK','CompanyName','EdgarTextUrl','EdgarHtmlUrl','AccessionNumber','FileDate_Plus_20','FileDate_Plus_20_Price','Share_Unit_Value_Raw','FileName','f_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12fdd5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileDate</th>\n",
       "      <th>SecFileName</th>\n",
       "      <th>CompanyTicker</th>\n",
       "      <th>FileDate_ClosingPrice</th>\n",
       "      <th>Pct_Change_20</th>\n",
       "      <th>file_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>UNF</td>\n",
       "      <td>133.860001</td>\n",
       "      <td>1.979676</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>LW</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>-5.583489</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>CCF</td>\n",
       "      <td>95.870003</td>\n",
       "      <td>1.648059</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>KMX</td>\n",
       "      <td>64.910004</td>\n",
       "      <td>-7.441075</td>\n",
       "      <td>2151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FileType   FileDate SecFileName CompanyTicker  FileDate_ClosingPrice  \\\n",
       "0     10-Q 2019-01-03   2019-QTR1           UNF             133.860001   \n",
       "1     10-Q 2019-01-04   2019-QTR1            LW              75.580002   \n",
       "2     10-Q 2019-01-08   2019-QTR1           CCF              95.870003   \n",
       "3     10-Q 2019-01-08   2019-QTR1           KMX              64.910004   \n",
       "\n",
       "   Pct_Change_20  file_text_length  \n",
       "0       1.979676              1870  \n",
       "1      -5.583489              1692  \n",
       "2       1.648059              2048  \n",
       "3      -7.441075              2151  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_text_features = df_non_text_features.reset_index(drop=True)\n",
    "df_non_text_features.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15a3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## extracting the month only from file date\n",
    "df_non_text_features['FileDate']=df_non_text_features.FileDate.astype('str')\n",
    "\n",
    "FileDate = df_non_text_features['FileDate']\n",
    "\n",
    "File_Mon = []\n",
    "\n",
    "for pd in FileDate:\n",
    "    mon = pd[5:7]\n",
    "    File_Mon.append(mon)\n",
    "    \n",
    "# adding the confromed period month to the dataframe\n",
    "df_non_text_features[\"File_Mon\"] = File_Mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e01a2b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 8.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## extracting the QTR only from SecFileName\n",
    "df_non_text_features['SecFileName']=df_non_text_features.SecFileName.astype('str')\n",
    "\n",
    "SecFileName = df_non_text_features['SecFileName']\n",
    "\n",
    "QTR = []\n",
    "\n",
    "for pd in SecFileName:\n",
    "    qtr = pd[5:9]\n",
    "    QTR.append(qtr)\n",
    "    \n",
    "# adding the confromed period month to the dataframe\n",
    "df_non_text_features[\"QTR\"] = QTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a719c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_non_text_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f969975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 281 ms\n",
      "Wall time: 270 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Converting Pct_Change_20  to boolean variable based on whether the change is exceeding 5%\n",
    "\n",
    "per_change_exceeding = []\n",
    "\n",
    "for index, row in df_non_text_features.iterrows():\n",
    "    if row['Pct_Change_20'] > 5:     \n",
    "          per_change_exceeding.append(\"True\")\n",
    "    else: \n",
    "        per_change_exceeding.append(\"False\")\n",
    "        \n",
    "df_non_text_features[\"per_change_exceeding\"] = per_change_exceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda19c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False', 'True'], dtype='<U5')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(per_change_exceeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7bd40af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileDate</th>\n",
       "      <th>SecFileName</th>\n",
       "      <th>CompanyTicker</th>\n",
       "      <th>FileDate_ClosingPrice</th>\n",
       "      <th>Pct_Change_20</th>\n",
       "      <th>file_text_length</th>\n",
       "      <th>File_Mon</th>\n",
       "      <th>QTR</th>\n",
       "      <th>per_change_exceeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>UNF</td>\n",
       "      <td>133.860001</td>\n",
       "      <td>1.979676</td>\n",
       "      <td>1870</td>\n",
       "      <td>01</td>\n",
       "      <td>QTR1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>LW</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>-5.583489</td>\n",
       "      <td>1692</td>\n",
       "      <td>01</td>\n",
       "      <td>QTR1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2019-QTR1</td>\n",
       "      <td>CCF</td>\n",
       "      <td>95.870003</td>\n",
       "      <td>1.648059</td>\n",
       "      <td>2048</td>\n",
       "      <td>01</td>\n",
       "      <td>QTR1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FileType    FileDate SecFileName CompanyTicker  FileDate_ClosingPrice  \\\n",
       "0     10-Q  2019-01-03   2019-QTR1           UNF             133.860001   \n",
       "1     10-Q  2019-01-04   2019-QTR1            LW              75.580002   \n",
       "2     10-Q  2019-01-08   2019-QTR1           CCF              95.870003   \n",
       "\n",
       "   Pct_Change_20  file_text_length File_Mon   QTR per_change_exceeding  \n",
       "0       1.979676              1870       01  QTR1                False  \n",
       "1      -5.583489              1692       01  QTR1                False  \n",
       "2       1.648059              2048       01  QTR1                False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_text_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "979fbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Droping filedate, Secfilename and Pct_Change_20 from the dataframe\n",
    "df_non_text_features = df_non_text_features.drop(columns = ['FileDate','SecFileName', 'Pct_Change_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90993627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## adding sector based on tickers\n",
    "# import yfinance as yf\n",
    "\n",
    "# tickers = df_non_text_features['CompanyTicker']\n",
    "# Sector = []\n",
    "\n",
    "# for ticker in tickers: \n",
    "#     try:\n",
    "#         sector = yf.Ticker(ticker).info['sector']       \n",
    "#     except:\n",
    "#         sector =\" \"\n",
    "#         print(sys.exc_info()[0], \"occurred.\")     \n",
    "#     Sector.append(sector) \n",
    "\n",
    "# print(len(Sector))\n",
    "# print(set(Sector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "509583a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# len(Sector)\n",
    "# print(set(Sector))\n",
    "# Counter(Sector).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f8016d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values, counts = np.unique(Sector, return_counts=True)\n",
    "# print(values, ' ', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "378ff117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileType</th>\n",
       "      <th>CompanyTicker</th>\n",
       "      <th>FileDate_ClosingPrice</th>\n",
       "      <th>file_text_length</th>\n",
       "      <th>File_Mon</th>\n",
       "      <th>QTR</th>\n",
       "      <th>per_change_exceeding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>UNF</td>\n",
       "      <td>133.860001</td>\n",
       "      <td>1870</td>\n",
       "      <td>01</td>\n",
       "      <td>QTR1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>LW</td>\n",
       "      <td>75.580002</td>\n",
       "      <td>1692</td>\n",
       "      <td>01</td>\n",
       "      <td>QTR1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>CCF</td>\n",
       "      <td>95.870003</td>\n",
       "      <td>2048</td>\n",
       "      <td>01</td>\n",
       "      <td>QTR1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FileType CompanyTicker  FileDate_ClosingPrice  file_text_length File_Mon  \\\n",
       "0     10-Q           UNF             133.860001              1870       01   \n",
       "1     10-Q            LW              75.580002              1692       01   \n",
       "2     10-Q           CCF              95.870003              2048       01   \n",
       "\n",
       "    QTR per_change_exceeding  \n",
       "0  QTR1                False  \n",
       "1  QTR1                False  \n",
       "2  QTR1                False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_text_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3227cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   000s  101in  10b  10b18  10b51 plan  10b51 trading plan  10e       10k  \\\n",
      "0   0.0    0.0  0.0    0.0         0.0                 0.0  0.0  0.000000   \n",
      "1   0.0    0.0  0.0    0.0         0.0                 0.0  0.0  0.000832   \n",
      "2   0.0    0.0  0.0    0.0         0.0                 0.0  0.0  0.000000   \n",
      "\n",
      "   10k 10q       10q  ...  yousc section  yousc section certification  \\\n",
      "0      0.0  0.000000  ...       0.000417                          0.0   \n",
      "1      0.0  0.000418  ...       0.000000                          0.0   \n",
      "2      0.0  0.000356  ...       0.000000                          0.0   \n",
      "\n",
      "   yousmanage banking office  youtube  ytd  zero percent  zero share  \\\n",
      "0                        0.0      0.0  0.0           0.0         0.0   \n",
      "1                        0.0      0.0  0.0           0.0         0.0   \n",
      "2                        0.0      0.0  0.0           0.0         0.0   \n",
      "\n",
      "   zip code  zone restriction  zoning  \n",
      "0       0.0               0.0     0.0  \n",
      "1       0.0               0.0     0.0  \n",
      "2       0.0               0.0     0.0  \n",
      "\n",
      "[3 rows x 43513 columns]\n",
      "====================================================================================================\n",
      "Size of the tfidf Vector Matrix:  (7820, 43513)\n",
      "CPU times: total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## tf-idf vectorizer for ngram text\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "MAX_FEATURES = 20000 \n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidvec = TfidfVectorizer(analyzer='word', \n",
    "                          tokenizer=dummy_fun,                      \n",
    "                          preprocessor=dummy_fun,\n",
    "                          token_pattern=None,\n",
    "#                           max_features = MAX_FEATURES,\n",
    "                          binary=True, \n",
    "                          smooth_idf=False,\n",
    "                          max_df=0.80,     \n",
    "                          min_df=0.005,       \n",
    "                          norm= 'l1',      ## increase the sparsity\n",
    "                          stop_words= None,\n",
    "                          strip_accents=None,\n",
    "                          use_idf=True,\n",
    "                          sublinear_tf=True)\n",
    "\n",
    "df_tfidvec = tfidvec.fit_transform(data_filingsize_price[\"f_text\"])\n",
    "\n",
    "dfsp_tfidf = pd.DataFrame(df_tfidvec.toarray(), columns=tfidvec.get_feature_names_out())\n",
    "print(dfsp_tfidf.head(3))\n",
    "print('='*100)\n",
    "print('Size of the tfidf Vector Matrix: ', dfsp_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b282242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tfidvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6153dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  final data frame \n",
    "import pandas as pd\n",
    "df_final = pd.concat([df_non_text_features, dfsp_tfidf], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd676d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7820 entries, 0 to 7819\n",
      "Columns: 43520 entries, FileType to zoning\n",
      "dtypes: float64(43514), int64(1), object(5)\n",
      "memory usage: 2.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e327910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 37.1 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "categorical_columns = ['FileType','CompanyTicker','File_Mon','QTR']\n",
    "\n",
    "for column in categorical_columns:\n",
    "#     print(column, ' ', df_final_2.dtypes[column])\n",
    "    tempdf = pd.get_dummies(df_final[column], prefix=column)\n",
    "    df_final = pd.merge(\n",
    "        left=df_final,\n",
    "        right=tempdf,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    df_final = df_final.drop(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3ec385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7820 entries, 0 to 7819\n",
      "Columns: 45023 entries, FileDate_ClosingPrice to QTR_QTR4\n",
      "dtypes: float64(43514), int64(1), object(1), uint8(1507)\n",
      "memory usage: 2.5+ GB\n",
      "CPU times: total: 11.5 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8c7ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.97 s\n",
      "Wall time: 1.97 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_final</th>\n",
       "      <td>2.67GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_filingsize_price</th>\n",
       "      <td>161.51MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_non_text_features</th>\n",
       "      <td>2.44MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileDate</th>\n",
       "      <td>511.80KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SecFileName</th>\n",
       "      <td>504.16KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_change_exceeding</th>\n",
       "      <td>67.53KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTR</th>\n",
       "      <td>67.53KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File_Mon</th>\n",
       "      <td>67.53KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_6</th>\n",
       "      <td>38.27KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempdf</th>\n",
       "      <td>30.69KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Size\n",
       "df_final                 2.67GB\n",
       "data_filingsize_price  161.51MB\n",
       "df_non_text_features     2.44MB\n",
       "FileDate               511.80KB\n",
       "SecFileName            504.16KB\n",
       "per_change_exceeding    67.53KB\n",
       "QTR                     67.53KB\n",
       "File_Mon                67.53KB\n",
       "_6                      38.27KB\n",
       "tempdf                  30.69KB"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# del data2\n",
    "# del data_filing_size\n",
    "# del dfsp_tfidf\n",
    "\n",
    "gc.collect()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1c4b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from scipy import sparse\n",
    "# df_final_comp = csr_matrix(df_final.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062c014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf274d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cb07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796d60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9983e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ploting the distribution of response variable \n",
    "missbeat_plot = sns.catplot(x=\"per_change_exceeding\", kind=\"count\",data=df_final,height=5, aspect=.5)\n",
    "missbeat_plot.fig.suptitle(\"'per_change_exceeding' Distribution\",\n",
    "                  fontsize=15, fontdict={\"weight\": \"bold\"})\n",
    "'''Though not perfect, it is not unbalanced '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36a26dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QR factorization to find the orthogonal columns to have a better conditioned matrix\n",
    "\n",
    "## DROP the response variable \n",
    "\n",
    "df_final_explantory = df_final.drop(columns = ['per_change_exceeding'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46466b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from scipy import sparse\n",
    "# df_final_explantory_comp = csr_matrix(df_final_explantory.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2e7c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Memory utilised (bytes): \", sys.getsizeof(df_final_explantory_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9771e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9447a9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f95bed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix condition:   1.2593810138696542e+21\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('matrix condition:  ', np.linalg.cond(df_final_explantory, p=None))\n",
    "\n",
    "'''it is an ill-conditioned matrix as the condition value is more than 2^16; so we need to use orthogonal bases'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6f6f7",
   "metadata": {},
   "source": [
    "## Using SVD decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed0d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## SVD\n",
    "# from numpy import dot, diag, exp, real, sin, cosh, tanh\n",
    "# from scipy.linalg import svd, svdvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e23b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def omega_approx(beta):\n",
    "#     \"\"\"Return an approximate omega value for given beta. Equation (5) from Gavish 2014.\"\"\"\n",
    "#     return 0.56 * beta**3 - 0.95 * beta**2 + 1.82 * beta + 1.43\n",
    "\n",
    "# df_final_explantory = df_final.drop(columns = ['per_change_exceeding'])\n",
    "\n",
    "# # do SVD and find tau star hat\n",
    "# U,sv,Vh = svd(df_final_explantory, False, lapack_driver='gesvd')\n",
    "# beta = min(df_final_explantory.shape) / max(df_final_explantory.shape)\n",
    "# tau = np.median(sv) * omega_approx(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecd64c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank = round(tau) + 1\n",
    "# print('Optimal Cutoff Ranks, after adjustment for rounding, for SVD as per Gavish and Donoho : ', rank) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "900e217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### top 7 column bases represent most of the variation\n",
    "# percentage_of_variation = round((sum(np.diagonal(np.diag(sv[:7]))) / sum(np.diagonal(np.diag(sv))))*100 , 2)\n",
    "\n",
    "# print('percentage of variation represented by 7 column bases :', percentage_of_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6551475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## taking top columns to create lower dimension matrix\n",
    "# df_lower = U[:,:7] \n",
    "# print('Size of the lower dimension matrix---')\n",
    "# print(df_lower.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53d881d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## weighting the column bases with the inverse of variation\n",
    "# # np.diag(sv[:7])\n",
    "# df_lower_new = U[:,:7] @ np.linalg.inv(np.diag(sv[:7]))\n",
    "# print('Size of the new lower dimension matrix---')\n",
    "# print(df_lower_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "441a1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_response = pd.DataFrame(per_change_exceeding, columns =['per_change_exceeding'])\n",
    "# df_response[\"per_change_exceeding\"] = (df_response[\"per_change_exceeding\"] == \"True\").astype(int)\n",
    "\n",
    "# print(df_response['per_change_exceeding'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8b8bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y = df_final['per_change_exceeding']  ## this is explanatory variable\n",
    "\n",
    "# y = np.array(df_response) ## already seperated from the data and stored in the y variable. converting to array\n",
    "# X = df_lower_new\n",
    "# print('Size of target vector: ', y.shape)\n",
    "# print('='*50)\n",
    "# print('Size of explanatory matrix: ',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1e2d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Since the data is somewhat unbalanced, I prefer to use StratifiedKFold\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# cv = StratifiedKFold(n_splits= 5,shuffle=True,random_state=42)\n",
    "\n",
    "# for train, test in cv.split(X,y):\n",
    "#     X_train = X[train] \n",
    "#     X_test  = X[test] \n",
    "#     y_train = y[train]\n",
    "#     y_test  = y[test] \n",
    "    \n",
    "# print('Size of training data: ', len(X_train), 'and its shape : ', X_train.shape)\n",
    "# print('Size of training labels: ', len(y_train), 'and its shape : ', y_train.shape)\n",
    "# print('Size of test data: ', len(X_test), 'and its shape : ', X_test.shape)\n",
    "# print('Size of test labels: ', len(y_test), 'and its shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b34e0f",
   "metadata": {},
   "source": [
    "## Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07befe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defining the architecture of this connected neural network\n",
    "\n",
    "# def build_fc_model():    \n",
    "#     '''defining the model using the Sequential class'''\n",
    "#     fc_model = tf.keras.Sequential([\n",
    "#       # First define a input layer\n",
    "#       tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "\n",
    "#       # Defining the activation function for the first fully connected (Dense) layer      \n",
    "#       tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "        \n",
    "#       # Defining the activation function for the second fully connected (Dense) layer      \n",
    "#       tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),     \n",
    "\n",
    "#       # Defining the activation function for the third fully connected (Dense) layer      \n",
    "#       tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),   \n",
    "        \n",
    "#       # Defining the second Dense layer to output the classification probabilities\n",
    "#       tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, activity_regularizer=tf.keras.regularizers.L2(0.01))       \n",
    "#     ])\n",
    "#     return fc_model\n",
    "\n",
    "# model = build_fc_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3045d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Using Adam optimizer with a learning rate of 0.01\n",
    "# ## since it is categorical classification, we are opting for caterorical_crossentropy for sparse data\n",
    "# ## chosing the matrix as accuracy\n",
    "\n",
    "# learning_rate = 0.0001\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40dbb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining the batch size and the number of epochs to use during training\n",
    "# BATCH_SIZE = 32\n",
    "# EPOCHS = 5\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69428a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29183945",
   "metadata": {},
   "source": [
    "## Using QR decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a8485682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.9 s\n",
      "Wall time: 5min 4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_final</th>\n",
       "      <td>1.89GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_final_explantory</th>\n",
       "      <td>1.89GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1.33GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_train_img</th>\n",
       "      <td>255.70MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_final_col_bases</th>\n",
       "      <td>130.77MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_q_col_bases</th>\n",
       "      <td>130.75MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>130.75MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>130.75MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_train</th>\n",
       "      <td>104.61MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_test_img</th>\n",
       "      <td>63.91MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Size\n",
       "df_final               1.89GB\n",
       "df_final_explantory    1.89GB\n",
       "r                      1.33GB\n",
       "X_train_img          255.70MB\n",
       "df_final_col_bases   130.77MB\n",
       "df_q_col_bases       130.75MB\n",
       "X                    130.75MB\n",
       "q                    130.75MB\n",
       "X_train              104.61MB\n",
       "X_test_img            63.91MB"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# del df_final\n",
    "# del df_non_text_features\n",
    "# del SecFileName\n",
    "# del FileDate\n",
    "# del QTR\n",
    "# del tempdf\n",
    "# del File_Mon\n",
    "\n",
    "gc.collect()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90f4dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## converting datatype from float64 to float32 to reduce the size of the matrix\n",
    "# for col in df_final_explantory.columns:\n",
    "#     if df_final_explantory[col].dtype == 'float64':\n",
    "#         df_final_explantory[col] = df_final_explantory[col].astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73798bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_final_explantory.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c779cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.3 s\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### QR factorization to find the orthogonal columns to have a better conditioned matrix\n",
    "\n",
    "# df_final_explantory = df_final.drop(columns = ['per_change_exceeding'])\n",
    "matrix = df_final_explantory.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50f94f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.94 s\n",
      "Wall time: 1.92 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_final</th>\n",
       "      <td>2.67GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_filingsize_price</th>\n",
       "      <td>161.51MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_non_text_features</th>\n",
       "      <td>2.44MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileDate</th>\n",
       "      <td>511.80KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SecFileName</th>\n",
       "      <td>504.16KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File_Mon</th>\n",
       "      <td>67.53KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_change_exceeding</th>\n",
       "      <td>67.53KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTR</th>\n",
       "      <td>67.53KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_6</th>\n",
       "      <td>38.27KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempdf</th>\n",
       "      <td>30.69KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Size\n",
       "df_final                 2.67GB\n",
       "data_filingsize_price  161.51MB\n",
       "df_non_text_features     2.44MB\n",
       "FileDate               511.80KB\n",
       "SecFileName            504.16KB\n",
       "File_Mon                67.53KB\n",
       "per_change_exceeding    67.53KB\n",
       "QTR                     67.53KB\n",
       "_6                      38.27KB\n",
       "tempdf                  30.69KB"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "del df_final_explantory\n",
    "\n",
    "gc.collect()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad77688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 54s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## qr factorization \n",
    "q, r = np.linalg.qr(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce4497bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7820, 45022)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d13c864b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7820, 7820)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1afb91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7820, 45022)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c16cf3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 68.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_7810</th>\n",
       "      <th>col_7811</th>\n",
       "      <th>col_7812</th>\n",
       "      <th>col_7813</th>\n",
       "      <th>col_7814</th>\n",
       "      <th>col_7815</th>\n",
       "      <th>col_7816</th>\n",
       "      <th>col_7817</th>\n",
       "      <th>col_7818</th>\n",
       "      <th>col_7819</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.007863</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.754513e-16</td>\n",
       "      <td>1.283718e-16</td>\n",
       "      <td>7.447396e-17</td>\n",
       "      <td>-2.471724e-18</td>\n",
       "      <td>-3.382243e-16</td>\n",
       "      <td>-1.252103e-17</td>\n",
       "      <td>-1.381784e-16</td>\n",
       "      <td>-3.154973e-17</td>\n",
       "      <td>7.293513e-18</td>\n",
       "      <td>-3.412533e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.007116</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>...</td>\n",
       "      <td>3.306694e-16</td>\n",
       "      <td>-1.651550e-17</td>\n",
       "      <td>-5.210623e-16</td>\n",
       "      <td>-5.128195e-16</td>\n",
       "      <td>2.114526e-16</td>\n",
       "      <td>4.299818e-17</td>\n",
       "      <td>-1.119074e-16</td>\n",
       "      <td>-1.850420e-16</td>\n",
       "      <td>2.167929e-16</td>\n",
       "      <td>-1.839293e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>-0.002280</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.410376e-16</td>\n",
       "      <td>4.615214e-17</td>\n",
       "      <td>4.514945e-16</td>\n",
       "      <td>6.310789e-16</td>\n",
       "      <td>8.856483e-17</td>\n",
       "      <td>-4.269309e-16</td>\n",
       "      <td>1.740894e-15</td>\n",
       "      <td>1.582384e-16</td>\n",
       "      <td>-4.446505e-16</td>\n",
       "      <td>-1.164409e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  7820 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0 -0.000126 -0.007863 -0.000528 -0.000398 -0.001002 -0.000316 -0.000826   \n",
       "1 -0.000071 -0.007116 -0.000478 -0.000360 -0.000907 -0.000286 -0.000747   \n",
       "2 -0.000090 -0.008613 -0.000578 -0.000436 -0.001098 -0.000346 -0.000904   \n",
       "\n",
       "      col_7     col_8     col_9  ...      col_7810      col_7811  \\\n",
       "0 -0.000761 -0.000347 -0.002086  ... -1.754513e-16  1.283718e-16   \n",
       "1 -0.000689 -0.000314  0.024632  ...  3.306694e-16 -1.651550e-17   \n",
       "2 -0.000834 -0.000380 -0.002280  ... -3.410376e-16  4.615214e-17   \n",
       "\n",
       "       col_7812      col_7813      col_7814      col_7815      col_7816  \\\n",
       "0  7.447396e-17 -2.471724e-18 -3.382243e-16 -1.252103e-17 -1.381784e-16   \n",
       "1 -5.210623e-16 -5.128195e-16  2.114526e-16  4.299818e-17 -1.119074e-16   \n",
       "2  4.514945e-16  6.310789e-16  8.856483e-17 -4.269309e-16  1.740894e-15   \n",
       "\n",
       "       col_7817      col_7818      col_7819  \n",
       "0 -3.154973e-17  7.293513e-18 -3.412533e-18  \n",
       "1 -1.850420e-16  2.167929e-16 -1.839293e-17  \n",
       "2  1.582384e-16 -4.446505e-16 -1.164409e-16  \n",
       "\n",
       "[3 rows x 7820 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "### putting the column bases (q) into dataframe\n",
    "\n",
    "column_bases = [f'col_{num}' for num in range(len(np.transpose(q)))]\n",
    "\n",
    "df_q_col_bases = pd.DataFrame(q, columns=column_bases)\n",
    "\n",
    "df_q_col_bases.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29d794c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per_change_exceeding</th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>...</th>\n",
       "      <th>col_7810</th>\n",
       "      <th>col_7811</th>\n",
       "      <th>col_7812</th>\n",
       "      <th>col_7813</th>\n",
       "      <th>col_7814</th>\n",
       "      <th>col_7815</th>\n",
       "      <th>col_7816</th>\n",
       "      <th>col_7817</th>\n",
       "      <th>col_7818</th>\n",
       "      <th>col_7819</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.007863</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.754513e-16</td>\n",
       "      <td>1.283718e-16</td>\n",
       "      <td>7.447396e-17</td>\n",
       "      <td>-2.471724e-18</td>\n",
       "      <td>-3.382243e-16</td>\n",
       "      <td>-1.252103e-17</td>\n",
       "      <td>-1.381784e-16</td>\n",
       "      <td>-3.154973e-17</td>\n",
       "      <td>7.293513e-18</td>\n",
       "      <td>-3.412533e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.007116</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>...</td>\n",
       "      <td>3.306694e-16</td>\n",
       "      <td>-1.651550e-17</td>\n",
       "      <td>-5.210623e-16</td>\n",
       "      <td>-5.128195e-16</td>\n",
       "      <td>2.114526e-16</td>\n",
       "      <td>4.299818e-17</td>\n",
       "      <td>-1.119074e-16</td>\n",
       "      <td>-1.850420e-16</td>\n",
       "      <td>2.167929e-16</td>\n",
       "      <td>-1.839293e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.410376e-16</td>\n",
       "      <td>4.615214e-17</td>\n",
       "      <td>4.514945e-16</td>\n",
       "      <td>6.310789e-16</td>\n",
       "      <td>8.856483e-17</td>\n",
       "      <td>-4.269309e-16</td>\n",
       "      <td>1.740894e-15</td>\n",
       "      <td>1.582384e-16</td>\n",
       "      <td>-4.446505e-16</td>\n",
       "      <td>-1.164409e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  7821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   per_change_exceeding     col_0     col_1     col_2     col_3     col_4  \\\n",
       "0                     0 -0.000126 -0.007863 -0.000528 -0.000398 -0.001002   \n",
       "1                     0 -0.000071 -0.007116 -0.000478 -0.000360 -0.000907   \n",
       "2                     0 -0.000090 -0.008613 -0.000578 -0.000436 -0.001098   \n",
       "\n",
       "      col_5     col_6     col_7     col_8  ...      col_7810      col_7811  \\\n",
       "0 -0.000316 -0.000826 -0.000761 -0.000347  ... -1.754513e-16  1.283718e-16   \n",
       "1 -0.000286 -0.000747 -0.000689 -0.000314  ...  3.306694e-16 -1.651550e-17   \n",
       "2 -0.000346 -0.000904 -0.000834 -0.000380  ... -3.410376e-16  4.615214e-17   \n",
       "\n",
       "       col_7812      col_7813      col_7814      col_7815      col_7816  \\\n",
       "0  7.447396e-17 -2.471724e-18 -3.382243e-16 -1.252103e-17 -1.381784e-16   \n",
       "1 -5.210623e-16 -5.128195e-16  2.114526e-16  4.299818e-17 -1.119074e-16   \n",
       "2  4.514945e-16  6.310789e-16  8.856483e-17 -4.269309e-16  1.740894e-15   \n",
       "\n",
       "       col_7817      col_7818      col_7819  \n",
       "0 -3.154973e-17  7.293513e-18 -3.412533e-18  \n",
       "1 -1.850420e-16  2.167929e-16 -1.839293e-17  \n",
       "2  1.582384e-16 -4.446505e-16 -1.164409e-16  \n",
       "\n",
       "[3 rows x 7821 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## new dataframe with response variable\n",
    "\n",
    "df_response = pd.DataFrame(per_change_exceeding, columns =['per_change_exceeding'])\n",
    "df_response[\"per_change_exceeding\"] = (df_response[\"per_change_exceeding\"] == \"True\").astype(int)\n",
    "\n",
    "df_final_col_bases = pd.concat([df_response, df_q_col_bases], axis=1, join='inner')\n",
    "df_final_col_bases.head(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28b39eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5967\n",
       "1    1853\n",
       "Name: per_change_exceeding, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_response['per_change_exceeding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a5b553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# del df_q_col_bases\n",
    "# del r\n",
    "# del q\n",
    "\n",
    "# gc.collect()\n",
    "# memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8eed2921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of target vector:  (7820,)\n",
      "==================================================\n",
      "Size of explanatory matrix:  (7820, 7820)\n"
     ]
    }
   ],
   "source": [
    "## X for explanatory variables and y for the response variable\n",
    "## Normalize explanatory variables \n",
    "y = df_final_col_bases['per_change_exceeding']\n",
    "X = df_final_col_bases.drop('per_change_exceeding', axis=1)\n",
    "\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# X = Normalizer().fit(X_raw)\n",
    "print('Size of target vector: ', y.shape)\n",
    "print('='*50)\n",
    "print('Size of explanatory matrix: ',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64f96bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# del df_final_col_bases\n",
    "\n",
    "# gc.collect()\n",
    "# memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "678eb2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  7299 and its shape :  (7299, 7820)\n",
      "Size of training labels:  7299 and its shape :  (7299,)\n",
      "Size of test data:  521 and its shape :  (521, 7820)\n",
      "Size of test labels:  521 and its shape :  (521,)\n"
     ]
    }
   ],
   "source": [
    "## Spliting data using stratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cross_val = StratifiedKFold(n_splits=15,shuffle=True,random_state=42)\n",
    "\n",
    "for train, test in cross_val.split(X,y):\n",
    "    X_train = X.iloc[train]\n",
    "    X_test  = X.iloc[test]\n",
    "    y_train = y.iloc[train]\n",
    "    y_test  = y.iloc[test] \n",
    "\n",
    "print('Size of training data: ', len(X_train), 'and its shape : ', X_train.shape)\n",
    "print('Size of training labels: ', len(y_train), 'and its shape : ', y_train.shape)\n",
    "print('Size of test data: ', len(X_test), 'and its shape : ', X_test.shape)\n",
    "print('Size of test labels: ', len(y_test), 'and its shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86928ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# del X\n",
    "\n",
    "# gc.collect()\n",
    "# memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40ee6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all of the explanatory features with StandardScaler in train and test sets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c5644e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c6331",
   "metadata": {},
   "source": [
    "## Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24d6bda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 500)               3910500   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1000)              501000    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 500)              2000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,916,501\n",
      "Trainable params: 4,914,501\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the architecture of this connected neural network\n",
    "\n",
    "def build_fc_model():    \n",
    "    '''defining the model using the Sequential class'''\n",
    "    fc_model = tf.keras.Sequential([\n",
    "      # First define a input layer\n",
    "      tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "\n",
    "      # Defining the activation function for the first fully connected (Dense) layer      \n",
    "      tf.keras.layers.Dense(500, activation=tf.nn.relu,  kernel_initializer = \"HeNormal\", use_bias = True, \n",
    "                           bias_initializer='HeNormal', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "        \n",
    "      # Normalizing the batch to prevent from exploding  \n",
    "      tf.keras.layers.BatchNormalization(),        \n",
    "        \n",
    "      # Adding dropout to prevent from overfitting\n",
    "      tf.keras.layers.Dropout(0.5),    \n",
    "        \n",
    "      # Defining the activation function for the second fully connected (Dense) layer      \n",
    "      tf.keras.layers.Dense(1000, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)),   \n",
    "\n",
    "      # adding dropout to prevent from overfitting \n",
    "      tf.keras.layers.Dropout(0.5),      \n",
    "        \n",
    "      # Defining the activation function for the third fully connected (Dense) layer      \n",
    "      tf.keras.layers.Dense(500, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(0.01)), \n",
    "        \n",
    "      # Normalizing the batch to prevent from exploding        \n",
    "      tf.keras.layers.BatchNormalization(),           \n",
    "        \n",
    "      # Defining the second Dense layer to output the classification probabilities\n",
    "      tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, activity_regularizer=tf.keras.regularizers.L2(0.01))       \n",
    "    ])\n",
    "    return fc_model\n",
    "\n",
    "model = build_fc_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b1baa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Adam optimizer with a learning rate of 0.01\n",
    "## since it is categorical classification, we are opting for caterorical_crossentropy for sparse data\n",
    "## chosing the matrix as accuracy\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76a80190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "229/229 [==============================] - 10s 42ms/step - loss: 22.1408 - accuracy: 0.5540\n",
      "Epoch 2/10\n",
      "229/229 [==============================] - 10s 42ms/step - loss: 18.6975 - accuracy: 0.6672\n",
      "Epoch 3/10\n",
      "229/229 [==============================] - 10s 42ms/step - loss: 15.9208 - accuracy: 0.7412\n",
      "Epoch 4/10\n",
      "229/229 [==============================] - 10s 43ms/step - loss: 13.5608 - accuracy: 0.8190\n",
      "Epoch 5/10\n",
      "229/229 [==============================] - 10s 46ms/step - loss: 11.4939 - accuracy: 0.9081\n",
      "Epoch 6/10\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 9.7192 - accuracy: 0.9468\n",
      "Epoch 7/10\n",
      "229/229 [==============================] - 11s 47ms/step - loss: 8.1669 - accuracy: 0.9671\n",
      "Epoch 8/10\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 6.8074 - accuracy: 0.9751\n",
      "Epoch 9/10\n",
      "229/229 [==============================] - 11s 48ms/step - loss: 5.6541 - accuracy: 0.9818\n",
      "Epoch 10/10\n",
      "229/229 [==============================] - 12s 51ms/step - loss: 4.7056 - accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2eda7edbbb0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the batch size and the number of epochs to use during training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91c8c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 14ms/step - loss: 5.4832 - accuracy: 0.7582\n",
      "Test loss: 5.483181953430176\n",
      "----------------------------\n",
      "Test accuracy: 0.7581573724746704\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model with the test data\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test) \n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('----------------------------')\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfab2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing the threshold for prediction \n",
    "\n",
    "prediction = model.predict(X_test) ## prediction probabilities\n",
    "\n",
    "actual_pred = []\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "for p in prediction: \n",
    "    if p > prediction_threshold: \n",
    "        pred = 1\n",
    "        actual_pred.append(pred)\n",
    "    else: \n",
    "        pred = 0\n",
    "        actual_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e663d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------------Confusion Report----------------------')\n",
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, actual_pred,  target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbf5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6933fa2e",
   "metadata": {},
   "source": [
    "## Converting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e351534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7820, 7820)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## shape of the matrix\n",
    "df_q_col_bases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b4ad526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABAklEQVR4nN3ZQQ6CQBBEUUdHkGhgwXm58xAUQUQ9hW/RXOCHVHdXUaTh8P8nnwWkCEgtIJuAdALyEpBVQFoBIcK/BSQJyCcM5CggFwGZBIS8CRF+EZBeQB4C0ggI8RPyJruA3AWEJEji8WS6soCQjT8JCDEtMsJE+K+AkNtFPJ5oQj4dyDISZ5zDQMh3/FVAnmEgZONvAkJMaxQQYlqk9iAjLDZetB5ohIkmpPYgI0xqdFI+VwJCposIT64waVNFc2cOJBlhUnQS4Um4Iz9pSKoXV9jsSREQ4vEEQuw3jmmJmGr2hBxIAhG5y2hCAjf5tUFuVxEQciBJS0TKZxJTRe76AT9CL/u0nB9yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100 at 0x2EDA4EDE490>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Converting images from the data row\n",
    "from PIL import Image \n",
    "images = df_q_col_bases.apply(lambda x: Image.fromarray(x.values.reshape(7820,1), 'L').resize((100, 100)), axis=1)\n",
    "\n",
    "# show image 0\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3e01957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image = images[0]\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fcdbea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_arr = np.array(images)\n",
    "## converting images (png) to tensor\n",
    "\n",
    "imagetensor = []\n",
    "\n",
    "for i in range(len(images)): \n",
    "    image_tensor = tf.convert_to_tensor(images[i])\n",
    "    imagetensor.append(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb741738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=uint8, numpy=\n",
       "array([[132, 132, 132, ..., 132, 132, 132],\n",
       "       [133, 133, 133, ..., 133, 133, 133],\n",
       "       [130, 130, 130, ..., 130, 130, 130],\n",
       "       ...,\n",
       "       [120, 120, 120, ..., 120, 120, 120],\n",
       "       [119, 119, 119, ..., 119, 119, 119],\n",
       "       [126, 126, 126, ..., 126, 126, 126]], dtype=uint8)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetensor[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "788ce756",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr = np.array(imagetensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23a1f9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132, 132, 132, ..., 132, 132, 132],\n",
       "       [133, 133, 133, ..., 133, 133, 133],\n",
       "       [130, 130, 130, ..., 130, 130, 130],\n",
       "       ...,\n",
       "       [120, 120, 120, ..., 120, 120, 120],\n",
       "       [119, 119, 119, ..., 119, 119, 119],\n",
       "       [126, 126, 126, ..., 126, 126, 126]], dtype=uint8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_arr[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40d6ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding training and testing impages\n",
    "X_train_img = image_arr[train]\n",
    "X_test_img = image_arr[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "944b3b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141, 141, 141, ..., 141, 141, 141],\n",
       "       [137, 137, 137, ..., 137, 137, 137],\n",
       "       [140, 140, 140, ..., 140, 140, 140],\n",
       "       ...,\n",
       "       [134, 134, 134, ..., 134, 134, 134],\n",
       "       [124, 124, 124, ..., 124, 124, 124],\n",
       "       [126, 126, 126, ..., 126, 126, 126]], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca82c0",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df45e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = X_train_img / 255\n",
    "X_test_img = X_test_img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "971f518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55294118, 0.55294118, 0.55294118, ..., 0.55294118, 0.55294118,\n",
       "        0.55294118],\n",
       "       [0.5372549 , 0.5372549 , 0.5372549 , ..., 0.5372549 , 0.5372549 ,\n",
       "        0.5372549 ],\n",
       "       [0.54901961, 0.54901961, 0.54901961, ..., 0.54901961, 0.54901961,\n",
       "        0.54901961],\n",
       "       ...,\n",
       "       [0.5254902 , 0.5254902 , 0.5254902 , ..., 0.5254902 , 0.5254902 ,\n",
       "        0.5254902 ],\n",
       "       [0.48627451, 0.48627451, 0.48627451, ..., 0.48627451, 0.48627451,\n",
       "        0.48627451],\n",
       "       [0.49411765, 0.49411765, 0.49411765, ..., 0.49411765, 0.49411765,\n",
       "        0.49411765]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fdffc72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7299, 100, 100)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0e1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "280e9f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 100, 100, 100)     2600      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 100)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 49, 49, 100)       250100    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               5760100   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,023,801\n",
      "Trainable params: 6,023,401\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## CNN architecture \n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Conv2D(100, (5,5), padding='same', kernel_initializer = \"HeNormal\", use_bias = True, \n",
    "                           bias_initializer='HeNormal', activation=\"relu\",input_shape=(100, 100, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((3, 3), strides=2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(100, (5,5), padding='same',activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D((3, 3), strides=2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation=\"softmax\")\n",
    "]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e9c67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Adam optimizer with a learning rate of 0.01\n",
    "## since it is categorical classification, we are opting for caterorical_crossentropy for sparse data\n",
    "## chosing the matrix as accuracy\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d53e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "229/229 [==============================] - 425s 2s/step - loss: 0.8037 - accuracy: 0.2369\n",
      "Epoch 2/5\n",
      "229/229 [==============================] - 493s 2s/step - loss: 0.7015 - accuracy: 0.2369\n",
      "Epoch 3/5\n",
      "229/229 [==============================] - 491s 2s/step - loss: 0.6634 - accuracy: 0.2369\n",
      "Epoch 4/5\n",
      "229/229 [==============================] - 493s 2s/step - loss: 0.6352 - accuracy: 0.2369\n",
      "Epoch 5/5\n",
      "229/229 [==============================] - 490s 2s/step - loss: 0.6138 - accuracy: 0.2369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2eda7b3ef70>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the batch size and the number of epochs to use during training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "model.fit(X_train_img, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e469e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 8s 482ms/step - loss: 0.5514 - accuracy: 0.2380\n",
      "Test loss: 0.551430344581604\n",
      "----------------------------\n",
      "Test accuracy: 0.23800383508205414\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model with the test data\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_img, y_test) \n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('----------------------------')\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db226b57",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5897981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 15, 20, None],\n",
      " 'max_leaf_nodes': [5, 10, 15],\n",
      " 'min_samples_leaf': [5, 10, 15],\n",
      " 'min_samples_split': [5, 10, 15],\n",
      " 'n_estimators': [50, 133, 216, 300]}\n"
     ]
    }
   ],
   "source": [
    "## grid parameters\n",
    "from pprint import pprint\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 4)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 20, num = 3)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [5, 10, 15]\n",
    "min_samples_leaf = [5, 10, 15]\n",
    "max_leaf_nodes = [5, 10,15]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, \n",
    "               'max_leaf_nodes' : max_leaf_nodes}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fdf850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# clf_rf = RandomForestClassifier()\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator = clf_rf, param_distributions = random_grid, n_iter = 250,  cv = None, scoring = 'accuracy',  verbose=2, random_state=21, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(X_train, y_train)\n",
    "# pprint(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed06c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Model Performance----------------\n",
      "Accuracy = 76.20%.\n",
      "-----------------------Confusion Report----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.76      1.00      0.86       397\n",
      "          No       0.00      0.00      0.00       124\n",
      "\n",
      "    accuracy                           0.76       521\n",
      "   macro avg       0.38      0.50      0.43       521\n",
      "weighted avg       0.58      0.76      0.66       521\n",
      "\n",
      "CPU times: total: 20min 57s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import  accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, n_estimators=500, \n",
    "                                random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "## Model evaluation \n",
    "predictions = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('-------------Model Performance----------------')   \n",
    "print('Accuracy = {:0.2%}.'.format(accuracy))\n",
    "\n",
    "print('-----------------------Confusion Report----------------------')\n",
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, predictions,  target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07d54c",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b895dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3487650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3h 39min 48s\n",
      "Wall time: 29min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=12, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=500,\n",
       "              n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "best_xgb = XGBClassifier(n_jobs=-1, \n",
    "#                             gamma= 2,\n",
    "                            learning_rate=0.2, \n",
    "                            n_estimators=500,\n",
    "#                             colsample_bytree=0.5,\n",
    "                            max_depth=12, \n",
    "#                             min_child_weight=0.5, \n",
    "#                             subsample=0.4,\n",
    "#                             objective='binary:logistic',\n",
    "#                             booster = 'dart',           \n",
    "#                             sample_type = 'weighted',\n",
    "#                             normalize_type = 'forest',\n",
    "#                             rate_drop = 0.15,\n",
    "#                             skip_drop = 0.6,\n",
    "                            random_state=42)\n",
    "\n",
    "best_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b3f6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Model Performance----------------\n",
      "Accuracy = 76.58%\n",
      "-----------------------Confusion Report----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.76      1.00      0.87       397\n",
      "          No       1.00      0.02      0.03       124\n",
      "\n",
      "    accuracy                           0.77       521\n",
      "   macro avg       0.88      0.51      0.45       521\n",
      "weighted avg       0.82      0.77      0.67       521\n",
      "\n",
      "CPU times: total: 1.22 s\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model evaluation \n",
    "yhat_xgb = best_xgb.predict(X_test) ## prediction \n",
    "accuracy = accuracy_score(y_test, yhat_xgb)\n",
    "\n",
    "print('-------------Model Performance----------------')   \n",
    "print('Accuracy = {:0.2%}'.format(accuracy))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('-----------------------Confusion Report----------------------')\n",
    "target_names = ['Yes', 'No']\n",
    "print(classification_report(y_test, yhat_xgb,  target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4161b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9cf666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e647fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a695359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaecbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
